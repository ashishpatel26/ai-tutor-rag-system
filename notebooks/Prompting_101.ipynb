{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPU9sEVDv5OVnuosoYOX+2r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ai-tutor-rag-system/blob/main/notebooks/Prompting_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Packages and Setup Variables"
      ],
      "metadata": {
        "id": "DMXyyXD0xix9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o4Q0N2omkAoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca915d08-f66b-4c57-b46b-f30dfd97a869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai==1.30.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the \"OPENAI_API_KEY\" in the Python environment. Will be used by OpenAI client later.\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"[YOUR_OPENAI_KEY]\""
      ],
      "metadata": {
        "id": "xxK7EAAvr2aT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the API client"
      ],
      "metadata": {
        "id": "68RbStS-xpbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Defining the \"client\" object that enables\n",
        "# us to connect to OpenAI API endpoints.\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "La8hdWqJkFkh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query the API"
      ],
      "metadata": {
        "id": "CC-sa_uv6J2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bad Prompt"
      ],
      "metadata": {
        "id": "tCgIt1OJH8-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "        model='gpt-4o',\n",
        "        temperature=0.0,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"How AI can help my project?\"}\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "_gSnVAvE0tGN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( response.choices[0].message.content )"
      ],
      "metadata": {
        "id": "ET_l06LiojaN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efc482d5-88f1-4a72-d2ca-fcfcfd095ea5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI can significantly enhance your project in various ways, depending on the nature and goals of your project. Here are some general areas where AI can be beneficial:\n",
            "\n",
            "### 1. **Data Analysis and Insights**\n",
            "- **Predictive Analytics:** AI can analyze historical data to predict future trends, helping you make informed decisions.\n",
            "- **Pattern Recognition:** AI algorithms can identify patterns and correlations in large datasets that might be missed by human analysis.\n",
            "- **Sentiment Analysis:** For projects involving customer feedback or social media, AI can gauge public sentiment and provide actionable insights.\n",
            "\n",
            "### 2. **Automation**\n",
            "- **Task Automation:** AI can automate repetitive tasks, freeing up time for more strategic activities.\n",
            "- **Process Optimization:** AI can streamline workflows and improve efficiency by optimizing various processes.\n",
            "\n",
            "### 3. **Personalization**\n",
            "- **Customized User Experience:** AI can tailor content, recommendations, and interactions based on user behavior and preferences.\n",
            "- **Targeted Marketing:** AI can help in segmenting your audience and delivering personalized marketing messages.\n",
            "\n",
            "### 4. **Natural Language Processing (NLP)**\n",
            "- **Chatbots and Virtual Assistants:** AI-powered chatbots can handle customer inquiries, provide support, and improve user engagement.\n",
            "- **Text Analysis:** AI can analyze and summarize large volumes of text, making it easier to extract relevant information.\n",
            "\n",
            "### 5. **Image and Video Analysis**\n",
            "- **Object Detection:** AI can identify and classify objects within images or videos, useful for projects involving surveillance, quality control, or content moderation.\n",
            "- **Facial Recognition:** AI can be used for security, user authentication, and personalized experiences.\n",
            "\n",
            "### 6. **Decision Support**\n",
            "- **Recommendation Systems:** AI can provide recommendations based on user behavior, preferences, and historical data.\n",
            "- **Risk Assessment:** AI can evaluate risks and provide insights to mitigate them, useful in finance, healthcare, and other sectors.\n",
            "\n",
            "### 7. **Innovation and Creativity**\n",
            "- **Content Generation:** AI can assist in generating content, such as articles, reports, or even creative writing.\n",
            "- **Design Assistance:** AI tools can help in creating designs, layouts, and prototypes.\n",
            "\n",
            "### 8. **Enhanced Security**\n",
            "- **Fraud Detection:** AI can identify unusual patterns and flag potential fraudulent activities.\n",
            "- **Threat Detection:** AI can monitor systems for security threats and vulnerabilities.\n",
            "\n",
            "### 9. **Scalability**\n",
            "- **Handling Large Datasets:** AI can process and analyze large volumes of data more efficiently than traditional methods.\n",
            "- **Real-time Processing:** AI can provide real-time analysis and insights, crucial for time-sensitive projects.\n",
            "\n",
            "### 10. **Cost Reduction**\n",
            "- **Resource Optimization:** AI can help in optimizing resource allocation, reducing waste, and lowering costs.\n",
            "- **Operational Efficiency:** By automating tasks and improving processes, AI can lead to significant cost savings.\n",
            "\n",
            "### Steps to Integrate AI into Your Project\n",
            "1. **Identify Needs:** Determine which aspects of your project can benefit from AI.\n",
            "2. **Choose the Right Tools:** Select AI tools and platforms that align with your project requirements.\n",
            "3. **Data Collection:** Gather and prepare the data needed for AI algorithms.\n",
            "4. **Model Training:** Train AI models using your data.\n",
            "5. **Implementation:** Integrate AI solutions into your project workflow.\n",
            "6. **Monitoring and Evaluation:** Continuously monitor AI performance and make adjustments as needed.\n",
            "\n",
            "By leveraging AI, you can enhance the efficiency, effectiveness, and innovation of your project. If you provide more specific details about your project, I can offer more tailored advice on how AI can be applied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Good Prompt"
      ],
      "metadata": {
        "id": "_Pyd2dmOH51S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "        model='gpt-4o',\n",
        "        temperature=0.0,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"How can I do summarization using AI?\"}\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "gHXHXUG09d4q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( response.choices[0].message.content )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K_aqbum9fef",
        "outputId": "3cfcf973-0c4e-404e-b207-d6b57646776c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarization using AI involves using machine learning models to condense a large body of text into a shorter version while retaining the key information and main ideas. There are two main types of summarization techniques: extractive and abstractive.\n",
            "\n",
            "1. **Extractive Summarization**: This method involves selecting important sentences, phrases, or sections directly from the original text and concatenating them to create a summary. It doesn't generate new sentences but rather extracts and combines parts of the original text.\n",
            "\n",
            "2. **Abstractive Summarization**: This method involves generating new sentences that convey the main ideas of the original text. It is more complex as it requires understanding the context and rephrasing the content in a concise manner.\n",
            "\n",
            "Here are some steps and tools you can use to perform summarization using AI:\n",
            "\n",
            "### Using Pre-trained Models and Libraries\n",
            "\n",
            "1. **Hugging Face Transformers**:\n",
            "   - Hugging Face provides a library called `transformers` which includes pre-trained models for both extractive and abstractive summarization.\n",
            "   - Example using Python:\n",
            "\n",
            "     ```python\n",
            "     from transformers import pipeline\n",
            "\n",
            "     # Load the summarization pipeline\n",
            "     summarizer = pipeline(\"summarization\")\n",
            "\n",
            "     # Your text to summarize\n",
            "     text = \"\"\"\n",
            "     Your long text goes here...\n",
            "     \"\"\"\n",
            "\n",
            "     # Generate summary\n",
            "     summary = summarizer(text, max_length=150, min_length=30, do_sample=False)\n",
            "     print(summary[0]['summary_text'])\n",
            "     ```\n",
            "\n",
            "2. **GPT-3 by OpenAI**:\n",
            "   - GPT-3 can be used for summarization tasks by providing it with appropriate prompts.\n",
            "   - Example using Python and OpenAI API:\n",
            "\n",
            "     ```python\n",
            "     import openai\n",
            "\n",
            "     openai.api_key = 'your-api-key'\n",
            "\n",
            "     response = openai.Completion.create(\n",
            "       engine=\"text-davinci-003\",\n",
            "       prompt=\"Summarize the following text:\\n\\nYour long text goes here...\",\n",
            "       max_tokens=150\n",
            "     )\n",
            "\n",
            "     summary = response.choices[0].text.strip()\n",
            "     print(summary)\n",
            "     ```\n",
            "\n",
            "3. **BERTSUM**:\n",
            "   - BERTSUM is a model based on BERT (Bidirectional Encoder Representations from Transformers) specifically fine-tuned for summarization tasks.\n",
            "   - You can find implementations and pre-trained models on GitHub and Hugging Face.\n",
            "\n",
            "### Using Online Tools\n",
            "\n",
            "1. **Google Colab**:\n",
            "   - You can use Google Colab to run summarization models without needing to set up a local environment. Many tutorials and notebooks are available online that demonstrate how to use summarization models.\n",
            "\n",
            "2. **AI-based Summarization Services**:\n",
            "   - There are several online services that offer text summarization using AI, such as:\n",
            "     - **SMMRY**: A simple tool for extractive summarization.\n",
            "     - **Resoomer**: Another tool for summarizing articles and documents.\n",
            "\n",
            "### Custom Training\n",
            "\n",
            "If you need a custom summarization model tailored to your specific domain, you can fine-tune a pre-trained model on your dataset. This involves:\n",
            "\n",
            "1. **Preparing a Dataset**: Collect a dataset of documents and their corresponding summaries.\n",
            "2. **Fine-tuning a Model**: Use frameworks like Hugging Face Transformers to fine-tune a pre-trained model on your dataset.\n",
            "3. **Evaluation**: Evaluate the performance of your model using metrics like ROUGE (Recall-Oriented Understudy for Gisting Evaluation).\n",
            "\n",
            "### Example of Fine-tuning with Hugging Face\n",
            "\n",
            "```python\n",
            "from transformers import BartTokenizer, BartForConditionalGeneration, Trainer, TrainingArguments\n",
            "\n",
            "# Load pre-trained model and tokenizer\n",
            "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
            "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
            "\n",
            "# Prepare your dataset\n",
            "train_dataset = ...  # Your training dataset\n",
            "val_dataset = ...    # Your validation dataset\n",
            "\n",
            "# Define training arguments\n",
            "training_args = TrainingArguments(\n",
            "    output_dir='./results',\n",
            "    num_train_epochs=3,\n",
            "    per_device_train_batch_size=4,\n",
            "    per_device_eval_batch_size=4,\n",
            "    warmup_steps=500,\n",
            "    weight_decay=0.01,\n",
            "    logging_dir='./logs',\n",
            "    logging_steps=10,\n",
            ")\n",
            "\n",
            "# Initialize Trainer\n",
            "trainer = Trainer(\n",
            "    model=model,\n",
            "    args=training_args,\n",
            "    train_dataset=train_dataset,\n",
            "    eval_dataset=val_dataset,\n",
            ")\n",
            "\n",
            "# Train the model\n",
            "trainer.train()\n",
            "```\n",
            "\n",
            "By following these steps and using the appropriate tools, you can effectively perform text summarization using AI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Failed Edge Case"
      ],
      "metadata": {
        "id": "p8MBdV_aH2Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "        model='gpt-4o',\n",
        "        temperature=0.0,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"How can I do summarization multiple documents using Google Gemini model?\"}\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "r7By9Sy498p9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( response.choices[0].message.content )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyIsGPp4AnVY",
        "outputId": "0fc515ef-2e5a-4146-ca57-2147d5a04610"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of my last update in October 2023, Google Gemini is a suite of AI models developed by Google, which includes capabilities for natural language understanding and generation. If you want to use Google Gemini for summarizing multiple documents, you would typically follow these steps:\n",
            "\n",
            "1. **Access the Model**: Ensure you have access to the Google Gemini model. This might be through an API provided by Google Cloud or another platform where the model is hosted.\n",
            "\n",
            "2. **Prepare Your Documents**: Gather the documents you want to summarize. Ensure they are in a format that can be processed by the model (e.g., plain text, PDF, etc.).\n",
            "\n",
            "3. **Preprocess the Documents**: Depending on the input requirements of the Gemini model, you might need to preprocess your documents. This could involve cleaning the text, removing unnecessary formatting, or splitting the documents into manageable chunks if they are too large.\n",
            "\n",
            "4. **API Integration**: Use the API provided by Google to interact with the Gemini model. You will need to authenticate your requests, typically using an API key or OAuth token.\n",
            "\n",
            "5. **Send Requests**: Send the documents to the model for summarization. This might involve sending each document individually or batching them together if the API supports it.\n",
            "\n",
            "6. **Handle Responses**: Collect the summaries returned by the model. You might need to post-process these summaries to combine them or format them as needed.\n",
            "\n",
            "Here is a simplified example using Python pseudocode to illustrate the process:\n",
            "\n",
            "```python\n",
            "import requests\n",
            "\n",
            "# Define your API endpoint and API key\n",
            "api_endpoint = \"https://api.google.com/gemini/summarize\"\n",
            "api_key = \"YOUR_API_KEY\"\n",
            "\n",
            "# Function to summarize a single document\n",
            "def summarize_document(document_text):\n",
            "    headers = {\n",
            "        \"Authorization\": f\"Bearer {api_key}\",\n",
            "        \"Content-Type\": \"application/json\"\n",
            "    }\n",
            "    data = {\n",
            "        \"document\": document_text\n",
            "    }\n",
            "    response = requests.post(api_endpoint, headers=headers, json=data)\n",
            "    if response.status_code == 200:\n",
            "        return response.json().get(\"summary\")\n",
            "    else:\n",
            "        raise Exception(f\"Error: {response.status_code}, {response.text}\")\n",
            "\n",
            "# List of documents to summarize\n",
            "documents = [\n",
            "    \"Document 1 text...\",\n",
            "    \"Document 2 text...\",\n",
            "    \"Document 3 text...\"\n",
            "]\n",
            "\n",
            "# Summarize each document\n",
            "summaries = []\n",
            "for doc in documents:\n",
            "    summary = summarize_document(doc)\n",
            "    summaries.append(summary)\n",
            "\n",
            "# Combine summaries if needed\n",
            "combined_summary = \"\\n\".join(summaries)\n",
            "\n",
            "print(\"Combined Summary:\")\n",
            "print(combined_summary)\n",
            "```\n",
            "\n",
            "### Important Considerations:\n",
            "- **API Limits**: Be aware of any rate limits or usage quotas associated with the API.\n",
            "- **Document Size**: Large documents might need to be split into smaller parts before summarization.\n",
            "- **Post-Processing**: Depending on the quality of the summaries, you might need to do some post-processing to ensure coherence and readability.\n",
            "\n",
            "### Alternative Approaches:\n",
            "- **Batch Processing**: If the API supports batch processing, you can send multiple documents in a single request to improve efficiency.\n",
            "- **Custom Models**: If you have specific requirements, consider fine-tuning a model on your dataset using Google Cloud's AI Platform.\n",
            "\n",
            "Always refer to the latest documentation provided by Google for the most accurate and up-to-date information on using the Gemini model for your specific use case.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MghL9RV5HngY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}