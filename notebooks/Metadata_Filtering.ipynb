{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ai-tutor-rag-system/blob/main/notebooks/Metadata_Filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zE1h0uQV7uT"
      },
      "source": [
        "# Install Packages and Setup Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QPJzr-I9XQ7l",
        "outputId": "3c4007c4-fdc0-40c7-f2db-2a41e2566498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.9/258.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.28.2 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.2 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.2 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index==0.10.37 openai==1.12.0 tiktoken==0.6.0 llama-index-vector-stores-qdrant==0.2.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riuXwpSPcvWC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the following API Keys in the Python environment. Will be used later.\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"[OPENAI_API_KEY]\"\n",
        "\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIEeZzqLbz0J"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkgi2OrYzF7q"
      },
      "source": [
        "# Load a Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oGT6crooSSj"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = OpenAI(temperature=0.9, model=\"gpt-4o-mini\", max_tokens=512)\n",
        "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BwVuJXlzHVL"
      },
      "source": [
        "# Create a VectoreStore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNY6mrk6BF7V"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "\n",
        "# qdrant_client = QdrantClient(location=\":memory:\")\n",
        "# or Persist storage\n",
        "qdrant_client = QdrantClient(path=\"/content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z109ur9OC7U_"
      },
      "outputs": [],
      "source": [
        "vector_store = QdrantVectorStore(client=qdrant_client, collection_name=\"ai_tutor_knowledge\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9JbAzFcjkpn"
      },
      "source": [
        "# Load the Dataset (JSON)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceveDuYdWCYk"
      },
      "source": [
        "## Download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "54d6dd83a5e34738a400f8473c311c8b",
            "6972a91dde7f40f396687f52b8c827e1",
            "aa08e58d1bf54984bf572689cca3a602",
            "b9bd79838a5643c68a60f6423686fd01",
            "7928a2cfc1d64dbc9726a0370de92e41",
            "ed031d7859fe433eb3effa2418966523",
            "56804db5a70045918ba1fafc1eba4746",
            "b4eb114f81864674824f692f4269f04f",
            "59020eea91de485eb3b8584e378dad7a",
            "f803e8b84d8e4be9897e0a4ffd83d5d8",
            "4bd06664651849b386e6365d249af0be"
          ]
        },
        "id": "wl_pbPvMlv1h",
        "outputId": "242d3557-fd52-4988-dbac-166627909f58"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54d6dd83a5e34738a400f8473c311c8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ai_tutor_knowledge.jsonl:   0%|          | 0.00/6.96M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "file_path = hf_hub_download(repo_id=\"jaiganesan/ai_tutor_knowledge\", filename=\"ai_tutor_knowledge.jsonl\",repo_type=\"dataset\",local_dir=\"/content\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWBLtDbUWJfA"
      },
      "source": [
        "## Read File\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "YizvmXPejkJE",
        "outputId": "b2260f31-685c-4449-9fad-daa9deeeb6c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Github Repo: https://github.com/vaibhawkhemka/ML-Umbrella/tree/main/NLP/Product-Categorization   From e-commerce to Customer support  all businesses require some kind of NER model to process huge amounts of texts from users.   To automate this whole  one requires NER models to extract relevant and important entities from text.   Final Result/OutputInput text = EL D68 (Green  32 GB) 3 GB RAM [3 GB RAM U+007C 32 GB ROM U+007C Expandable Upto 128 GB  15.46 cm (6.088 inch) Display  13MP Rear Camera U+007C 8MP Front Camera  4000 mAh Battery  Quad-Core Processor]   Output =   Green ->>>> COLOR 32 GB ->>>> STORAGE 3 GB RAM ->>>> RAM 3 GB RAM ->>>> RAM 32 GB ROM ->>>> STORAGE Expandable Upto 128 GB ->>>> EXPANDABLE_STORAGE 15.46 cm (6.088 inch) ->>>> SCREEN_SIZE 13MP Rear Camera ->>>> BACK_CAMERA 8MP Front Camera ->>>> FRONT_CAMERA 4000 mAh Battery ->>>> BATTERY_CAPACITY Quad-Core Processor ->>>> PROCESSOR_CORE   Data PreparationA tool for creating this dataset (https://github.com/tecoholic/ner-annotator)    Snapshot for the dataset for Mobile phone product description on Amazon:   A single record of the Data:   Converting into proper Spacy span format:The proper format that Spacy Ner model understands   import jsonlines  json file_path = Training Data/Mobile/Mobile_training.jsonl laptop_classes = [RAM STORAGE BATTERY CAPACITY PROCESSOR_TYPE SCREEN_SIZE REFRESH_RATE SCREEN_TYPE BACK_CAMERA FRONT_CAMERA] with jsonlines.open(file_path) as reader: output_json = {classes: laptop_classes  annotations: []} # Iterate over each line (JSON object) for obj in reader: processed_obj = [obj[text] {entities:obj[label]}] output_json[annotations].append(processed_obj) # Save the output JSON to a new file with open('Training Data/Mobile/Mobile_annotations.json'  'w') as f: json.dump(output_json  f  indent=None)Above is the code for converting into proper data format. Check out jupyter notebook: NER_model_Mobile.ipynb   Final pandas dataframe from processed data:   Splitting the dataset  10% test### Split the data from sklearn.model_selection import train_test_split train  test = train_test_split(df  test_size=0.1) train.head()Create spacy DocBin objects from annotated data to train Spacy NER model:import spacy from spacy.tokens import DocBin from tqdm import tqdm # Define a function to create spaCy DocBin objects from the annotated data def get_spacy_doc(data): # Create a blank spaCy pipeline nlp = spacy.blank('en') db = DocBin() # Initialize a counter for None spans none_spans = 0 spans = 0 for index  row in data.iterrows(): # Get the text and annotations text = row[Description] annotations = row[Annotations] # Check if the text is not empty if not text: continue # Process the text and annotations doc = nlp(text) if doc is None: print(fFailed to process text: {text}) continue ents = [] for start  end  label in annotations: if start < 0 or end < 0: print(fInvalid annotation: {start}  {end}  {label}) continue #print(text) span = doc.char_span(start  end  label=label) if span is None: print(fFailed to create span for annotation: {start}  {end}  {label}) none_spans += 1 continue else: spans+=1 ents.append(span) doc.ents = ents #Add the processed document to the DocBin db.add(doc) print(fNumber of None spans: {none_spans}) print(fNumber of spans: {spans}) return dbModellingArchitecture:The basic architecture for all spacy models:   Reference: https://explosion.ai/blog/deep-learning-formula-nlp   [Embed]HashEmbed  Sub-word features than character based richer representation and arbitrary sized vocabulary  Can use Word2vec/Glove etc   [Encode]  Context-independent to context-dependent using LSTM or CNN.   [Attend]  Attention mechanism by Key  Value pair  and context vectors   [Predict]  MLP   Tok2vec model [example]:   https://github.com/explosion/spaCy/blob/master/spacy/ml/models/tok2vec.py (Built using thinc framework)   NER Model  Transition-Based:   State(all three stack  buffer  and output) and Action   Structure Prediction.   The above shows how the transition-based approach works with stack  buffer  output  and Transition/action.   Reference: https://www.microsoft.com/en-us/research/video/transition-based-natural-language-processing/   The above shows How stacked LSTM works for encoding for all states and actions.   The final Prediction from MLP is the Multiclassification task with labels as SHIFT  OUT  and REDUCE   Spacy model layer and Config Mapping:   Example of a tok2vec config:   Model in thinc framework:   Respective config for the model:   Thinc deep learning framework is used as a backend to build spacy models instead of pytorch or TensorFlow.   Difference between normal pytorch and spacy models. => Spacy(easy  reliable and productionable)   The user can define and create this model using a configuration file for any task: NER  Tok2Vec  Tagger  Dependency Parser  Sentiment etc   One can also create thinc models and wrap around pytorch and TensorFlow. I will build it next blog.   NER Config file created here:   Reference: https://spacy.io/usage/training   config_ner.cfg :   [paths] train = null dev = null vectors = en_core_web_lg init_tok2vec = null [system] gpu_allocator = null seed = 0 [nlp] lang = en pipeline = [tok2vec ner] batch_size = 1000 disabled = [] before_creation = null after_creation = null after_pipeline_creation = null tokenizer = {@tokenizers:spacy.Tokenizer.v1} vectors = {@vectors:spacy.Vectors.v1} [components] [components.ner] factory = ner incorrect_spans_key = null moves = null scorer = {@scorers:spacy.ner_scorer.v1} update_with_oracle_cut_size = 100 [components.ner.model] @architectures = spacy.TransitionBasedParser.v2 state_type = ner extra_state_tokens = false hidden_width = 64 maxout_pieces = 2 use_upper = true nO = null [components.ner.model.tok2vec] @architectures = spacy.Tok2VecListener.v1 width = ${components.tok2vec.model.encode.width} upstream = * [components.tok2vec] factory = tok2vec [components.tok2vec.model] @architectures = spacy.Tok2Vec.v2 [components.tok2vec.model.embed] @architectures = spacy.MultiHashEmbed.v2 width = ${components.tok2vec.model.encode.width} attrs = [NORM PREFIX SUFFIX SHAPE] rows = [5000 1000 2500 2500] include_static_vectors = true [components.tok2vec.model.encode] @architectures = spacy.MaxoutWindowEncoder.v2 width = 256 depth = 8 window_size = 1 maxout_pieces = 3 [corpora] [corpora.dev] @readers = spacy.Corpus.v1 path = ${paths.dev} max_length = 0 gold_preproc = false limit = 0 augmenter = null [corpora.train] @readers = spacy.Corpus.v1 path = ${paths.train} max_length = 0 gold_preproc = false limit = 0 augmenter = null [training] dev_corpus = corpora.dev train_corpus = corpora.train seed = ${system.seed} gpu_allocator = ${system.gpu_allocator} dropout = 0.1 accumulate_gradient = 1 patience = 1600 max_epochs = 0 max_steps = 20000 eval_frequency = 200 frozen_components = [] annotating_components = [] before_to_disk = null before_update = null [training.batcher] @batchers = spacy.batch_by_words.v1 discard_oversize = false tolerance = 0.2 get_length = null [training.batcher.size] @schedules = compounding.v1 start = 100 stop = 1000 compound = 1.001 t = 0.0 [training.logger] @loggers = spacy.ConsoleLogger.v1 progress_bar = false [training.optimizer] @optimizers = Adam.v1 beta1 = 0.9 beta2 = 0.999 L2_is_weight_decay = true L2 = 0.01 grad_clip = 1.0 use_averages = false eps = 0.00000001 learn_rate = 0.001 [training.score_weights] ents_f = 1.0 ents_p = 0.0 ents_r = 0.0 ents_per_type = null [pretraining] [initialize] vectors = ${paths.vectors} init_tok2vec = ${paths.init_tok2vec} vocab_data = null lookups = null before_init = null after_init = null [initialize.components] [initialize.tokenizer]Output and Evaluation:Evaluation is done based on ENTS_P(Precision)  ENTS_R(Recall) and ENTS_F (F-Score).   After the 15th epoch Final ENTS_F is 57.64  which can be improved by providing more data for this case.   Intuition for Evaluation:We evaluate the NER model based on Span-Identification and Span-Prediction.   Span-Identification:   https://cees-roele.medium.com/custom-evaluation-of-spans-in-spacy-f1f2e7a99ad8   As discussed  NER is a multiclass Classification problem with SHIFT  OUT  and REDUCE as output. But we evaluate our models only based on REDUCE.   The above picture shows how Precision  Recall  and F-Score are calculated.   The code used for evaluating PRF (Precision-Recall-Fscore) by spacy:   def get_ner_prf(examples: Iterable[Example]  **kwargs) -> Dict[str  Any]: Compute micro-PRF and per-entity PRF scores for a sequence of examples. score_per_type = defaultdict(PRFScore) for eg in examples: if not eg.y.has_annotation(ENT_IOB): continue golds = {(e.label_  e.start  e.end) for e in eg.y.ents} align_x2y = eg.alignment.x2y for pred_ent in eg.x.ents: if pred_ent.label_ not in score_per_type: score_per_type[pred_ent.label_] = PRFScore() indices = align_x2y[pred_ent.start : pred_ent.end] if len(indices): g_span = eg.y[indices[0] : indices[-1] + 1] # Check we aren't missing annotation on this span. If so  # our prediction is neither right nor wrong  we just # ignore it. if all(token.ent_iob != 0 for token in g_span): key = (pred_ent.label_  indices[0]  indices[-1] + 1) if key in golds: score_per_type[pred_ent.label_].tp += 1 golds.remove(key) else: score_per_type[pred_ent.label_].fp += 1 for label  start  end in golds: score_per_type[label].fn += 1 totals = PRFScore() for prf in score_per_type.values(): totals += prf if len(totals) > 0: return { ents_p: totals.precision  ents_r: totals.recall  ents_f: totals.fscore  ents_per_type: {k: v.to_dict() for k  v in score_per_type.items()}  } else: return { ents_p: None  ents_r: None  ents_f: None  ents_per_type: None  }Reference: https://github.com/explosion/spaCy/blob/master/spacy/scorer.py#L760   Span Prediction :   There are 9 different entires like [RAM  STORAGE  BATTERY CAPACITY  PROCESSOR_TYPE  SCREEN_SIZE  REFRESH_RATE  SCREEN_TYPE  BACK_CAMERA  FRONT_CAMERA] to predict for REDUCE class.   It uses categorical crossentropy loss function to optimize NER models (More details in later blogs)   Testing and Final Results:Input text = EL D68 (Green  32 GB) 3 GB RAM [3 GB RAM U+007C 32 GB ROM U+007C Expandable Upto 128 GB  15.46 cm (6.088 inch) Display  13MP Rear Camera U+007C 8MP Front Camera  4000 mAh Battery  Quad-Core Processor]   Output =   Green ->>>> COLOR 32 GB ->>>> STORAGE 3 GB RAM ->>>> RAM 3 GB RAM ->>>> RAM 32 GB ROM ->>>> STORAGE Expandable Upto 128 GB ->>>> EXPANDABLE_STORAGE 15.46 cm (6.088 inch) ->>>> SCREEN_SIZE 13MP Rear Camera ->>>> BACK_CAMERA 8MP Front Camera ->>>> FRONT_CAMERA 4000 mAh Battery ->>>> BATTERY_CAPACITY Quad-Core Processor ->>>> PROCESSOR_CORE   Github Link: https://github.com/vaibhawkhemka/ML-Umbrella/tree/main/NLP/Product-Categorization   Thanks for reading the blog.   If you have any questions  hit me up on my LinkedIn: https://www.linkedin.com/in/vaibhaw-khemka-a92156176/   References for modeling:   https://explosion.ai/blog/deep-learning-formula-nlp => Embed  Encode  Attend and Predict => Position is imp in sequence in text.   https://support.prodi.gy/t/spacy-ner-models-architecture-details/4336   https://github.com/explosion/spaCy/blob/master/spacy/ml/models/tok2vec.py   https://spacy.io/usage/layers-architectures   https://spacy.io/api/architectures#CharacterEmbed   Understanding span:   https://spacy.io/api/span\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "with open(file_path, \"r\") as file:\n",
        "    ai_tutor_knowledge = [json.loads(line) for line in file]\n",
        "ai_tutor_knowledge[1]['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_V99H1V2hck"
      },
      "outputs": [],
      "source": [
        "# Not necessary to use full dataset\n",
        "documents = ai_tutor_knowledge[:100]+ai_tutor_knowledge[500:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjuLbmFuWsyl"
      },
      "source": [
        "# Transforming\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IHtzr52E132e",
        "outputId": "be0a14dc-fe28-4965-cfac-eca91e9bebff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(id_='45501b72-9391-529e-8e5e-59a2604ba26e', embedding=None, metadata={'url': 'https://towardsai.net/p/machine-learning/adaboost-explained-from-its-original-paper', 'title': 'AdaBoost Explained From Its Original Paper', 'tokens': 1697, 'source': 'tai_blog'}, excluded_embed_metadata_keys=['url', 'tokens', 'source'], excluded_llm_metadata_keys=['title', 'tokens', 'source'], relationships={}, text=\"This publication is meant to show a very popular ML algorithm in complete detail  how it works  the math behind it  how to execute it in Python and an explanation of the proofs of the original paper. There will be math and code  but it is written in a way that allows you to decide which are the fun parts.   A bit on the origins of the algorithm: It was proposed by Yoav Freund and Robert E. Schapire in a 1997 paper  A Decision-Theoretic Generalization of On-Line Learning and an Application to Boostinga beautiful and brilliant publication for an effective and useful algorithm.   Lets start with the pros  cons  and uses of AdaBoost.   Advantages: improves performance and achieves higher accuracy than a single model. It reduces overfitting compared to some other machine learning algorithms.   Disadvantages: AdaBoost can be sensitive to noisy data and outliers. It requires careful tuning  and the performance can depend on the choice of weak learners and the number of iterations. It cannot be parallelized (or only partially)  since each predictor can only be trained after the previous predictor has been trained and evaluated. As a result  it does not scale as well as bagging or pasting.   Applications: image recognition  text classification  fraud detection  predictive modeling.   Introduction  what is ensemble learning and boosting?Python script with an Ada Boost algorithm  lets go straight to using this toolAda Boost explanation  the math on how it worksAda Boost example  simplifying the math  an example of one iterationReferencesIntroductionLets talk a bit about the wisdom of the crowd. Wisdom of the crowd is a phenomenon that suggests that the collective judgment of a diverse number of people is often surprisingly accurate. This mainly occurs because of the central limit theorem  which states that when you take an average of a large number of independent observations  the distribution will center around the true value.   Lets explain this with an example. What if there was a competition where people had to guess how many bubble gum pieces were in a jar? Thousands of different (independent) people will guess; some might be close  and others will be quite far from the true number  but once we calculate the average of the guesses  we will be quite close to the actual number of bubble gum balls  this my friends is the wisdom of the crowd.   How does this apply to Machine Learning?   If we have many predictors (decision trees  other classifiers or regressors) and we aggregate the predictions of this group  they will often perform better than the best individual predictor. A group of predictors is called an ensemble  thus  this technique is called Ensemble Learning.   AdaBoost belongs to a method called boosting. Boosting refers to any ensemble method that combines several weak learners (simple models) into a strong learner (a more accurate model).   There are many boosting methods  the most popular by far are Ada Boosting and Gradient Boosting.   Ada Boost with Python and Scikit-LearnPart 1: data preparationWe create a dummy dataset and separate the data into train and test.   import numpy as np from sklearn.datasets import make_classification from sklearn.model_selection import train_test_split # Generate a random dataset (for example purposes) X  y = make_classification(n_samples=100  n_features=2  n_informative=2  n_redundant=0  random_state=42) # Split the dataset into training and testing sets X_train  X_test  y_train  y_test = train_test_split(X  y  test_size=0.3  random_state=42)Part 2: AdaBoost with Decision Trees (1 branch)First  lets understand the possible parameters in Scikit-learns AdaBoostClassifier:   estimator: The base estimator from which the boosted ensemble is built. Usually  a decision tree with a max depth 1 (a weak learner).n_estimators: The maximum number of estimators at which boosting is terminated.learning rate: Weight applied to each classifier at each boosting iteration. A higher learning rate increases the contribution of each classifier.random_state: Controls the random seed given at each estimator at each boosting iteration.from sklearn.ensemble import AdaBoostClassifier from sklearn.tree import DecisionTreeClassifier # Create the AdaBoost classifier # Notice that the depth of the decision tree is 1 base_estimator = DecisionTreeClassifier(max_depth=1) ada_boost = AdaBoostClassifier(estimator=base_estimator  n_estimators=50  learning_rate=1.0  random_state=42) # Train the classifier ada_boost.fit(X_train  y_train) # Make predictions y_pred = ada_boost.predict(X_test)Part 3: Model evaluationWe measure the metrics of the model. Interpretation of these metrics will be seen in a different article.   from sklearn.metrics import accuracy_score  classification_report # Evaluate the classifier accuracy = accuracy_score(y_test  y_pred) print(f'Accuracy: {accuracy:.2f}') print('Classification Report:') print(classification_report(y_test  y_pred))Accuracy: 0.97 Classification Report: precision recall f1-score support 0 1.00 0.94 0.97 16 1 0.93 1.00 0.97 14 accuracy 0.97 30 macro avg 0.97 0.97 0.97 30 weighted avg 0.97 0.97 0.97 30Part 4: Plotting Resultsimport matplotlib.pyplot as plt # Plotting the decision boundary x_min  x_max = X[:  0].min() - 1  X[:  0].max() + 1 y_min  y_max = X[:  1].min() - 1  X[:  1].max() + 1 xx  yy = np.meshgrid(np.arange(x_min  x_max  0.01)  np.arange(y_min  y_max  0.01)) Z = ada_boost.predict(np.c_[xx.ravel()  yy.ravel()]) Z = Z.reshape(xx.shape) plt.contourf(xx  yy  Z  alpha=0.3) plt.scatter(X[:  0]  X[:  1]  c=y  edgecolors='k'  marker='o') plt.title('AdaBoost Decision Boundary') plt.xlabel('Feature 1') plt.ylabel('Feature 2') plt.show()Ada Boost ExplanationIn this section  we explain the key concepts and how an iteration works (a bit of math included  folks.   AdaBoost  short for Adaptive Boosting  is a machine learning algorithm that is used to improve the performance of other machine learning algorithms. We will define a few key concepts to explain how it works:   Weak Learners: models that perform slightly better than random guessing. Decision trees with one split are often used.Boosting: the process of combining multiple weak learners to form a strong learner. Each learner has a weight based on the performance of the previous learners.Weight Adjustment: First  all data points have equal weights. After each iteration  the weight of incorrectly classified points is increased; that way  the learner focuses more on the difficult cases.Combining Learners: the final model is a weighted sum of all the weak learners; each learners contribution to the final model is based on its accuracy  and more accurate learners are given higher weights.Algorithm stepsThe image shows how the algorithm improves on each iteration on separating between the blue and red dots. Lets find out how each step works.   Initialize Weights:Assign equal weights to all data points (each predictor).2. Train Weak Learner and Calculate Weighted Error   Train a weak learner on the weighted dataset (h_t).Calculate the error rate of the weak learner.3. Calculate Alpha  the learner's weight   4. Update weights   5. Combine weak learners   Example of one iterationInitialize weights   Train Weak Learner and Calculate Weighted Error   Calculate Alpha   Update weights   This process continues for each iteration.   ReferencesA Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting (1997)  Yoav Freund and Robert E. SchapireHands-On Machine Learning with Scikit-Learn  Keras  and TensorFlow (2019)  Aurelin GernSklearn documentation\", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import List\n",
        "from llama_index.core import Document\n",
        "\n",
        "def create_docs_from_list(data_list: List[dict]) -> List[Document]:\n",
        "    documents = []\n",
        "    for data in data_list:\n",
        "        documents.append(\n",
        "            Document(\n",
        "                doc_id=data[\"doc_id\"],\n",
        "                text=data[\"content\"],\n",
        "                metadata={  # type: ignore\n",
        "                    \"url\": data[\"url\"],\n",
        "                    \"title\": data[\"name\"],\n",
        "                    \"tokens\": data[\"tokens\"],\n",
        "                    \"source\": data[\"source\"],\n",
        "                },\n",
        "                excluded_llm_metadata_keys=[\n",
        "                    \"title\",\n",
        "                    \"tokens\",\n",
        "                    \"source\",\n",
        "                ],\n",
        "                excluded_embed_metadata_keys=[\n",
        "                    \"url\",\n",
        "                    \"tokens\",\n",
        "                    \"source\",\n",
        "                ],\n",
        "            )\n",
        "        )\n",
        "    return documents\n",
        "\n",
        "doc = create_docs_from_list(documents)\n",
        "doc[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z3t70DGWsjO"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "\n",
        "# Define the splitter object that split the text into segments with 512 tokens,\n",
        "# with a 128 overlap between the segments.\n",
        "text_splitter = TokenTextSplitter(separator=\" \", chunk_size=512, chunk_overlap=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "ee480100bb154436baa77f7646eac8a9",
            "1d2165e31a1844ab9b2622e2c026eafc",
            "7a0082fd01d94f1ea26ba5a7fa46888d",
            "0fa669303e8f4576b33500cc6f9cbb03",
            "fe1c96b3f95642319355ef1a0cfbdfeb",
            "6f661a40f974471cb794c6c8cb5443a5",
            "bd17db5471e74332990098ad91e66e7e",
            "1869b710e6e94dd9bb86e95f551cd468",
            "e6c9d0b0516b4e41b3b851674eeab05f",
            "7bf016a2ad90407585307c91ca8e7503",
            "3e6266125e0f46249c5aa3f2e2055883",
            "84aabee6cd5648f9b197c53fda78c9ce",
            "1012c8d8604345ebbd481da20003a0df",
            "07fd0784cd354676b0b24752bcffb3ff",
            "efc8f191a76149a3a20199d93e367f3b",
            "1e384601d23c4acb918b9ee98c35507e",
            "98d0351792ca402481eba68e5f3a5e0b",
            "814d96fed16a4b82bc2225d0f761ef4a",
            "afca0df6fc8546d9b9a3ca46ff5a70d7",
            "80f81c806e404045a059be2c9f705245",
            "bb658f259eb64d22abfbe5c8c5608eae",
            "0a9a09dc5839400f82ead38e046d2068"
          ]
        },
        "id": "P9LDJ7o-Wsc-",
        "outputId": "a0c71373-769c-4d90-fdf7-7c2c1625a63d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/362 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee480100bb154436baa77f7646eac8a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1181/1181 [04:11<00:00,  4.69it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/1181 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84aabee6cd5648f9b197c53fda78c9ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.vector_stores.qdrant.base:Collection ai_tutor_knowledge already exists, skipping collection creation.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.extractors import (\n",
        "    KeywordExtractor,\n",
        ")\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "\n",
        "# Create the pipeline to apply the transformation on each chunk,\n",
        "# and store the transformed text in the chroma vector store.\n",
        "pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        text_splitter,\n",
        "        KeywordExtractor(keywords=10, llm=Settings.llm),\n",
        "        OpenAIEmbedding(model=\"text-embedding-3-small\"),\n",
        "    ],\n",
        "    vector_store=vector_store,\n",
        ")\n",
        "\n",
        "# Run the transformation pipeline.\n",
        "nodes = pipeline.run(documents=doc, show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCeItuK-coeN",
        "outputId": "82fd2730-e7ff-4efd-9804-b0ed9c97e0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/collection/ai_tutor_knowledge/ (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "!zip ai_tutor_knowledge_metadata.zip /content/collection/ai_tutor_knowledge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPGa85hM2P3P",
        "outputId": "6c962613-cc7b-4699-efbe-99fab31bf5bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1181"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "len(nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03xtKcBanBDL",
        "outputId": "49e816aa-75c5-416f-d129-0395bd33401b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'url': 'https://towardsai.net/p/machine-learning/bert-huggingface-model-deployment-using-kubernetes-github-repo-03-07-2024',\n",
              " 'title': 'BERT HuggingFace Model Deployment using Kubernetes [ Github Repo]  03/07/2024',\n",
              " 'tokens': 768,\n",
              " 'source': 'tai_blog',\n",
              " 'excerpt_keywords': 'BERT, HuggingFace, Kubernetes, model deployment, FastAPI, Docker, scalability, containerization, ML pipeline, inference'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "nodes[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKXURvLtkuTS"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# Create the index based on the vector store.\n",
        "index = VectorStoreIndex.from_vector_store(vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine(similarity_top_k=10)\n",
        "res = query_engine.query(\"Explain how Advance RAG works?\")\n",
        "\n",
        "res.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "lrOMyoH38bDC",
        "outputId": "4e75ef16-72e8-43f9-edad-560e41108db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Advanced RAG systems, such as Self-Reflective RAG (Self-RAG) and Corrective RAG (CRAG), enhance the performance of traditional Retrieval-Augmented Generation by improving the quality of contextual information used during the generation process. Self-RAG employs instruction-tuning techniques to create self-reflection tags that guide the language model in dynamically retrieving relevant documents and critically assessing their relevance before generating responses. This self-reflective approach helps ensure that the information used in the generation is both relevant and high-quality.\\n\\nOn the other hand, CRAG introduces an external evaluator to assess and refine the retrieved documents before they are utilized in the generation process. This external evaluator ensures that only the most relevant and high-quality documents are considered, addressing potential retrieval errors that could hinder the generation output.\\n\\nTogether, these advanced systems focus on optimizing the retrieval process and the quality of the information fed into the language models, thus leading to more accurate and contextually rich responses compared to standard RAG approaches.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyL-j2xZ7V6d"
      },
      "source": [
        "# Metadata Filtering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saug9jxugX0P"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.vector_stores import MetadataFilter, MetadataFilters, FilterOperator\n",
        "\n",
        "filters = MetadataFilters(\n",
        "    filters=[\n",
        "        MetadataFilter(\n",
        "            key=\"excerpt_keywords\",\n",
        "            operator=FilterOperator.TEXT_MATCH,\n",
        "            value=\"PEFT\",\n",
        "        ),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JPD8yAinVSq"
      },
      "source": [
        "# Query Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0gue7cyctt1"
      },
      "outputs": [],
      "source": [
        "# Define a query engine that is responsible for retrieving related pieces of text,\n",
        "# and using a LLM to formulate the final answer.\n",
        "query_engine = index.as_query_engine(filters=filters)\n",
        "\n",
        "res = query_engine.query(\"How Parameter efficient fine tuning (PEFT) Works?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "VKK3jMprctre",
        "outputId": "e3dafe5f-a3c9-429c-c5f5-a8281e15f859"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Parameter Efficient Fine Tuning (PEFT) involves a more economical approach to training large language models by minimizing the computational costs associated with full fine-tuning. Instead of adjusting all weights in a model, PEFT focuses on specific strategies to efficiently update only a subset of parameters.\\n\\n1. **Selective Fine-tuning**: This approach selectively picks a subset of the model's initial parameters to optimize, reducing the overall number of parameters that require adjustment.\\n\\n2. **Reparameterization**: This method involves reparameterizing the model weights using a low-rank representation, which compresses the weight matrices and allows for more efficient training. \\n\\nBy employing these strategies, PEFT significantly cuts down on the resources needed, enabling effective model training while preserving most of the knowledge embedded in the pre-trained models.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "res.response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "465dH4yQc7Ct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac146ed-4938-4f98-cfdc-2b8b3f0b2a4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node ID\t 8075d3d3-beb5-471f-b70c-024775830fd9\n",
            "Title\t Fine-Tuning and Evaluating Large Language Models: Key Benchmarks and Metrics\n",
            "Text\t SAMSUM is one of the datasets that FLAN T5 uses. There are several pre-trained FLAN T5 models that have been fine-tuned on SAMSUM  including Phil Schmid/flan-t5-base-samsum and jasonmcaffee/flan-t5-large-samsum on Hugging Face. If we want to fine-tune the FLAN T5 model specifically for formal dialogue conversations  we can do so using the DIALOGUESUM dataset.   Models fine-tuned on DialogSum can be applied to areas like customer support  meeting minutes generation  chatbot summarization  and more.   2. PEFT (Parameter efficient fine tuning)Training LLMs is computationally intensive. Full finetuning is computationally expensive as it might change each weight in the model. First  we start with a pretrained LLM like GPT-3. This model already has a vast amount of knowledge and understanding of language. Then we provide task-specific datasets  which could be data for question answering or sentiment analysis or any other customer dataset. During training  full finetuning process makes slight adjustments to every weight in the pretrained model. While the model weights are substantial  we have other important aspects during training like Optimizer  which adds up to the cost. For example  Optimizer States  gradients  forward activation  and temporary memory. These additional components add up to the training cost.   Three main approaches are used in PEFT: Selective / reparameterization/additive.   1. SelectiveHere  we select a subset of initial LLM parameters to fine-tune.   2. ReparameterizationWe reparameterize model weights using a low-rank representation. We will discuss LoRA in detail below.   LORA: Low Rank Representation:   Each layer in a transformer architecture has multiple weight matrices for different operations  like self-attention or feed-forward networks. These matrices can have different sizes depending on the specific layer and configuration. Let us take an example by picking a matrix of size 512 x 64 = 32 768 parameters. Let us now see LoRA with rank = 8.   Original Weight Matrix: Dimensions: 512 x 64  Parameters: 32 768 (512 x 64)Matrix A (Rank Decomposition):\n",
            "Score\t 0.5624156315461442\n",
            "Score\t FLAN T5, SAMSUM, DIALOGUESUM, fine-tuning, Parameter Efficient Fine Tuning, PEFT, LoRA, large language models, computational cost, customer support\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
            "Node ID\t f7a1f4ff-b92a-4fad-8374-ad810accc369\n",
            "Title\t Fine-Tuning and Evaluating Large Language Models: Key Benchmarks and Metrics\n",
            "Text\t SAMSUM is one of the datasets that FLAN T5 uses. There are several pre-trained FLAN T5 models that have been fine-tuned on SAMSUM  including Phil Schmid/flan-t5-base-samsum and jasonmcaffee/flan-t5-large-samsum on Hugging Face. If we want to fine-tune the FLAN T5 model specifically for formal dialogue conversations  we can do so using the DIALOGUESUM dataset.   Models fine-tuned on DialogSum can be applied to areas like customer support  meeting minutes generation  chatbot summarization  and more.   2. PEFT (Parameter efficient fine tuning)Training LLMs is computationally intensive. Full finetuning is computationally expensive as it might change each weight in the model. First  we start with a pretrained LLM like GPT-3. This model already has a vast amount of knowledge and understanding of language. Then we provide task-specific datasets  which could be data for question answering or sentiment analysis or any other customer dataset. During training  full finetuning process makes slight adjustments to every weight in the pretrained model. While the model weights are substantial  we have other important aspects during training like Optimizer  which adds up to the cost. For example  Optimizer States  gradients  forward activation  and temporary memory. These additional components add up to the training cost.   Three main approaches are used in PEFT: Selective / reparameterization/additive.   1. SelectiveHere  we select a subset of initial LLM parameters to fine-tune.   2. ReparameterizationWe reparameterize model weights using a low-rank representation. We will discuss LoRA in detail below.   LORA: Low Rank Representation:   Each layer in a transformer architecture has multiple weight matrices for different operations  like self-attention or feed-forward networks. These matrices can have different sizes depending on the specific layer and configuration. Let us take an example by picking a matrix of size 512 x 64 = 32 768 parameters. Let us now see LoRA with rank = 8.   Original Weight Matrix: Dimensions: 512 x 64  Parameters: 32 768 (512 x 64)Matrix A (Rank Decomposition):\n",
            "Score\t 0.5545111748706848\n",
            "Score\t Keywords: FLAN T5, SAMSUM, DIALOGUESUM, PEFT, fine-tuning, large language models, LoRA, parameter efficient, computational cost, chatbot summarization\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
          ]
        }
      ],
      "source": [
        "# Show the retrieved nodes\n",
        "for src in res.source_nodes:\n",
        "    print(\"Node ID\\t\", src.node_id)\n",
        "    print(\"Title\\t\", src.metadata[\"title\"])\n",
        "    print(\"Text\\t\", src.text)\n",
        "    print(\"Score\\t\", src.score)\n",
        "    print(\"Score\\t\", src.metadata[\"excerpt_keywords\"])\n",
        "    print(\"-_\" * 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjwq8BRzNGUy"
      },
      "source": [
        "# Filter Metadata (source_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82mM9wqkM0jr"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.vector_stores import MetadataFilter,MetadataFilters,FilterOperator,FilterCondition\n",
        "\n",
        "filters = MetadataFilters(\n",
        "    filters=[\n",
        "        MetadataFilter(\n",
        "            key=\"excerpt_keywords\",\n",
        "            operator=FilterOperator.TEXT_MATCH,\n",
        "            value=\"BERT\",\n",
        "        ),\n",
        "        MetadataFilter(\n",
        "            key=\"source\", operator=FilterOperator.EQ, value=\"tai_blog\"\n",
        "        ),\n",
        "    ],\n",
        "    condition=FilterCondition.AND,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX4UUuLEM6NK"
      },
      "outputs": [],
      "source": [
        "# Define a query engine that is responsible for retrieving related pieces of text,\n",
        "# and using a LLM to formulate the final answer.\n",
        "query_engine = index.as_query_engine(filters=filters)\n",
        "\n",
        "result = query_engine.query(\"Explain BERT?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "mo3_T2fnM7yP",
        "outputId": "240227f4-e98b-449f-a96e-4ed976433f6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'BERT, which stands for Bidirectional Encoder Representations from Transformers, is a language model developed by Google that utilizes transformer architecture. It is designed to understand and generate human-like language by processing text in both directions simultaneously. This bidirectional capability allows BERT to capture context more effectively than traditional models that read text sequentially.\\n\\nFor example, in a sentence with a blank, BERT considers the entire context—both preceding and following words—to make a more accurate prediction about the missing word. BERT is available in two versions: BERT BASE and BERT LARGE, differing in the number of layers, parameters, and hidden units.\\n\\nThe model was pre-trained on a significant amount of text, approximately 3.3 billion words, through two main tasks: Masked Language Modeling (MLM) and Next Sentence Prediction (NSP). In MLM, some words in a sentence are masked, and BERT learns to predict those based on surrounding context. In NSP, it predicts whether one sentence is likely to follow another. This training allows BERT to produce contextualized vectors, enhancing its understanding of language.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "result.response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxnS44WtM9Dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe70553f-1937-40ed-a314-2cec6b008365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node ID\t 527f1ba7-ea18-48ac-9f08-3f0082892f9b\n",
            "Title\t Attention is all you need: How Transformer Architecture in NLP started.\n",
            "Text\t GPT-2  GPT-3  and GPT-4  which were decoder-only architectures. Another well-known example is BERT (Bidirectional Encoder Representations from Transformers)  an encoder-only transformer mode used as a component in sentence embedding models.   Lets talk about BERT!BERT stands for Bidirectional Encoder Representations from Transformers. It is a language model by Google that uses a transformer architecture to understand and generate human-like language. BERT is designed to simultaneously process text in both directions  allowing it to capture context more effectively than traditional unidirectional models  which read text sequentially from left to right or right to left.   Example of Bidirectional CapabilityConsider the sentence:    The bank is situated on the _______ of the river.   In a unidirectional model  understanding the blank would primarily rely on the words before it  potentially leading to ambiguity about whether bank refers to a financial institution or the side of a river.   However  BERTs bidirectional approach allows it to use the entire sentences context  including the words before and after the blank. Thus  the missing word is likely related to the river  resulting in a more accurate prediction  such as bank referring to the riverbank rather than a financial institution.   BERT has two versions:   BERT BASE with    Layers: 12Parameters: 110MAttention Heads: 12Hidden Units: 768BERT LARGE with    Layers: 24Parameters: 340MAttention Heads: 12Hidden Units: 1024DYK?BERT was pre-trained on 3.3 Billion words!   What was it pre-trained on? For what?BERT was pre-trained on two tasks:   Masked Language Modeling (MLM):The inputs are sentences that start with a special token called CLS (Classify Token) and end with a SEP (separator token).   Words  tokens (consider)   Around 15% of the input tokens are masked  and the model is trained to predict those masked tokens.   The model learns to produce contextualized vectors based on the surrounding words at this stage. Read the example above and reread this sentence.   Next Sentence Prediction (NSP):In this one  the model predicts if one sentence is likely to follow another.\n",
            "Score\t 0.6606314875064883\n",
            "Score\t Transformer, BERT, Bidirectional, Language Model, Masked Language Modeling, Next Sentence Prediction, Contextualized Vectors, Encoder, NLP, Google\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
            "Node ID\t 3c140fb8-4b61-4d97-8d86-9c0cfcad737a\n",
            "Title\t Attention is all you need: How Transformer Architecture in NLP started.\n",
            "Text\t GPT-2  GPT-3  and GPT-4  which were decoder-only architectures. Another well-known example is BERT (Bidirectional Encoder Representations from Transformers)  an encoder-only transformer mode used as a component in sentence embedding models.   Lets talk about BERT!BERT stands for Bidirectional Encoder Representations from Transformers. It is a language model by Google that uses a transformer architecture to understand and generate human-like language. BERT is designed to simultaneously process text in both directions  allowing it to capture context more effectively than traditional unidirectional models  which read text sequentially from left to right or right to left.   Example of Bidirectional CapabilityConsider the sentence:    The bank is situated on the _______ of the river.   In a unidirectional model  understanding the blank would primarily rely on the words before it  potentially leading to ambiguity about whether bank refers to a financial institution or the side of a river.   However  BERTs bidirectional approach allows it to use the entire sentences context  including the words before and after the blank. Thus  the missing word is likely related to the river  resulting in a more accurate prediction  such as bank referring to the riverbank rather than a financial institution.   BERT has two versions:   BERT BASE with    Layers: 12Parameters: 110MAttention Heads: 12Hidden Units: 768BERT LARGE with    Layers: 24Parameters: 340MAttention Heads: 12Hidden Units: 1024DYK?BERT was pre-trained on 3.3 Billion words!   What was it pre-trained on? For what?BERT was pre-trained on two tasks:   Masked Language Modeling (MLM):The inputs are sentences that start with a special token called CLS (Classify Token) and end with a SEP (separator token).   Words  tokens (consider)   Around 15% of the input tokens are masked  and the model is trained to predict those masked tokens.   The model learns to produce contextualized vectors based on the surrounding words at this stage. Read the example above and reread this sentence.   Next Sentence Prediction (NSP):In this one  the model predicts if one sentence is likely to follow another.\n",
            "Score\t 0.6574066078930942\n",
            "Score\t Keywords: Transformer Architecture, BERT, Bidirectional Encoding, Language Model, Masked Language Modeling, Next Sentence Prediction, Contextual Understanding, NLP, Google, Sentence Embedding\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
          ]
        }
      ],
      "source": [
        "# Show the retrieved nodes\n",
        "for src in result.source_nodes:\n",
        "    print(\"Node ID\\t\", src.node_id)\n",
        "    print(\"Title\\t\", src.metadata[\"title\"])\n",
        "    print(\"Text\\t\", src.text)\n",
        "    print(\"Score\\t\", src.score)\n",
        "    print(\"Score\\t\", src.metadata[\"excerpt_keywords\"])\n",
        "    print(\"-_\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q39sOYGIQhqm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When Mismatch between Keyword (value) and Query\n",
        "\n",
        "filters = MetadataFilters(\n",
        "    filters=[\n",
        "        MetadataFilter(\n",
        "            key=\"excerpt_keywords\",\n",
        "            operator=FilterOperator.TEXT_MATCH,\n",
        "            value=\"BERT\",\n",
        "        ),\n",
        "        MetadataFilter(\n",
        "            key=\"source\", operator=FilterOperator.EQ, value=\"tai_blog\"\n",
        "        ),\n",
        "    ],\n",
        "    condition=FilterCondition.AND,\n",
        ")\n",
        "\n",
        "query_engine = index.as_query_engine(filters=filters)\n",
        "\n",
        "result = query_engine.query(\"Explain PEFT?\")\n",
        "\n",
        "print(result.response)\n",
        "\n",
        "\n",
        "# Show the retrieved nodes\n",
        "for src in result.source_nodes:\n",
        "    print(\"Node ID\\t\", src.node_id)\n",
        "    print(\"Title\\t\", src.metadata[\"title\"])\n",
        "    print(\"Text\\t\", src.text)\n",
        "    print(\"Score\\t\", src.score)\n",
        "    print(\"Score\\t\", src.metadata[\"excerpt_keywords\"])\n",
        "    print(\"-_\" * 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23zPrDo9gojf",
        "outputId": "2cb53508-4b89-4850-d2a7-b144b9bb37b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided information does not mention PEFT or provide details about it. Therefore, I am unable to explain PEFT based on the available context.\n",
            "Node ID\t 637d10d8-d7a4-4352-81e2-48a21a9a3cf8\n",
            "Title\t Month in 4 Papers (June 2023)\n",
            "Text\t not needing to train a reward model is that it is more feasible to train models with fewer resources and fewer trials.   Experiments were conducted to evaluate the performance of LLMs tuned with DPO and PPO. The models were tested on the HH-RLHF dialogue task and two coding tasks. The results demonstrated that PPO consistently improves the models performance on complex tasks such as coding. They also discovered that using iterative DPO  which involves generating additional data with the newly trained rewards model during the tuning process  is more effective. However  PPO still outperforms DPO and achieves state-of-the-art results on challenging coding tasks.   Lastly  the ablation study highlights the crucial elements for the success of PPO training: normalizing advantages  using large batch sizes  and updating the reference model parameters with an exponential moving average.   No Attention?U+1F4DD Pretraining Without Attention [paper]   The idea is to explore if we can match the performance of the transformer-based models without an attention mechanism. They propose an architecture based on the combination of State-Space models (SSMs) and multiplicative gating.   They replaced the attention-based routing with the State-Space models. (High-level overview coming details not necessary for now!) These models describe a systems behaviour by linking unobservable variables to controllable inputs and measurable outputs. The model offers a method to achieve long-range dependencies similar to RNNs with the training speed of CNNs. Interestingly  they achieved comparable accuracy to BERT on the GLUE benchmark by simply matching the number of parameters!   The BiGS model does not exhibit quadratic complexity in relation to the length seen in transformers; instead  its complexity is linear at 2L. The paper suggests that this model may be the first to rival transformers without using attention. This fascinating research indicates that the transformer architecture isnt inherently unique or special. There may be other architectures using the same components but arranged differently that perform similarly yet more efficiently.   Maybe we should focus on finding different architectures and techniques at the same time that we are scaling the transformer to jizilion parameters :)   I send out a monthly newsletter for NLP nerds. Consider subscribing if you like to stay up-to-date on the latest developments in Natural Language Processing. Read more and subscribe  join the cool kids club and sign up now!   Final Words Please\n",
            "Score\t 0.25315574863862944\n",
            "Score\t Keywords: Machine Learning, DPO, PPO, LLMs, State-Space Models, Attention Mechanism, BERT, GLUE Benchmark, Natural Language Processing, Architecture Optimization\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
            "Node ID\t 3c140fb8-4b61-4d97-8d86-9c0cfcad737a\n",
            "Title\t Attention is all you need: How Transformer Architecture in NLP started.\n",
            "Text\t GPT-2  GPT-3  and GPT-4  which were decoder-only architectures. Another well-known example is BERT (Bidirectional Encoder Representations from Transformers)  an encoder-only transformer mode used as a component in sentence embedding models.   Lets talk about BERT!BERT stands for Bidirectional Encoder Representations from Transformers. It is a language model by Google that uses a transformer architecture to understand and generate human-like language. BERT is designed to simultaneously process text in both directions  allowing it to capture context more effectively than traditional unidirectional models  which read text sequentially from left to right or right to left.   Example of Bidirectional CapabilityConsider the sentence:    The bank is situated on the _______ of the river.   In a unidirectional model  understanding the blank would primarily rely on the words before it  potentially leading to ambiguity about whether bank refers to a financial institution or the side of a river.   However  BERTs bidirectional approach allows it to use the entire sentences context  including the words before and after the blank. Thus  the missing word is likely related to the river  resulting in a more accurate prediction  such as bank referring to the riverbank rather than a financial institution.   BERT has two versions:   BERT BASE with    Layers: 12Parameters: 110MAttention Heads: 12Hidden Units: 768BERT LARGE with    Layers: 24Parameters: 340MAttention Heads: 12Hidden Units: 1024DYK?BERT was pre-trained on 3.3 Billion words!   What was it pre-trained on? For what?BERT was pre-trained on two tasks:   Masked Language Modeling (MLM):The inputs are sentences that start with a special token called CLS (Classify Token) and end with a SEP (separator token).   Words  tokens (consider)   Around 15% of the input tokens are masked  and the model is trained to predict those masked tokens.   The model learns to produce contextualized vectors based on the surrounding words at this stage. Read the example above and reread this sentence.   Next Sentence Prediction (NSP):In this one  the model predicts if one sentence is likely to follow another.\n",
            "Score\t 0.2462708204669232\n",
            "Score\t Keywords: Transformer Architecture, BERT, Bidirectional Encoding, Language Model, Masked Language Modeling, Next Sentence Prediction, Contextual Understanding, NLP, Google, Sentence Embedding\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W784Vs7lg4fA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bd06664651849b386e6365d249af0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54d6dd83a5e34738a400f8473c311c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6972a91dde7f40f396687f52b8c827e1",
              "IPY_MODEL_aa08e58d1bf54984bf572689cca3a602",
              "IPY_MODEL_b9bd79838a5643c68a60f6423686fd01"
            ],
            "layout": "IPY_MODEL_7928a2cfc1d64dbc9726a0370de92e41"
          }
        },
        "56804db5a70045918ba1fafc1eba4746": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59020eea91de485eb3b8584e378dad7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6972a91dde7f40f396687f52b8c827e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed031d7859fe433eb3effa2418966523",
            "placeholder": "​",
            "style": "IPY_MODEL_56804db5a70045918ba1fafc1eba4746",
            "value": "ai_tutor_knowledge.jsonl: 100%"
          }
        },
        "7928a2cfc1d64dbc9726a0370de92e41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa08e58d1bf54984bf572689cca3a602": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4eb114f81864674824f692f4269f04f",
            "max": 6960611,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59020eea91de485eb3b8584e378dad7a",
            "value": 6960611
          }
        },
        "b4eb114f81864674824f692f4269f04f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9bd79838a5643c68a60f6423686fd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f803e8b84d8e4be9897e0a4ffd83d5d8",
            "placeholder": "​",
            "style": "IPY_MODEL_4bd06664651849b386e6365d249af0be",
            "value": " 6.96M/6.96M [00:00&lt;00:00, 8.87MB/s]"
          }
        },
        "ed031d7859fe433eb3effa2418966523": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f803e8b84d8e4be9897e0a4ffd83d5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee480100bb154436baa77f7646eac8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d2165e31a1844ab9b2622e2c026eafc",
              "IPY_MODEL_7a0082fd01d94f1ea26ba5a7fa46888d",
              "IPY_MODEL_0fa669303e8f4576b33500cc6f9cbb03"
            ],
            "layout": "IPY_MODEL_fe1c96b3f95642319355ef1a0cfbdfeb"
          }
        },
        "1d2165e31a1844ab9b2622e2c026eafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f661a40f974471cb794c6c8cb5443a5",
            "placeholder": "​",
            "style": "IPY_MODEL_bd17db5471e74332990098ad91e66e7e",
            "value": "Parsing nodes: 100%"
          }
        },
        "7a0082fd01d94f1ea26ba5a7fa46888d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1869b710e6e94dd9bb86e95f551cd468",
            "max": 362,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6c9d0b0516b4e41b3b851674eeab05f",
            "value": 362
          }
        },
        "0fa669303e8f4576b33500cc6f9cbb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bf016a2ad90407585307c91ca8e7503",
            "placeholder": "​",
            "style": "IPY_MODEL_3e6266125e0f46249c5aa3f2e2055883",
            "value": " 362/362 [00:04&lt;00:00, 295.48it/s]"
          }
        },
        "fe1c96b3f95642319355ef1a0cfbdfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f661a40f974471cb794c6c8cb5443a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd17db5471e74332990098ad91e66e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1869b710e6e94dd9bb86e95f551cd468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c9d0b0516b4e41b3b851674eeab05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bf016a2ad90407585307c91ca8e7503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6266125e0f46249c5aa3f2e2055883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84aabee6cd5648f9b197c53fda78c9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1012c8d8604345ebbd481da20003a0df",
              "IPY_MODEL_07fd0784cd354676b0b24752bcffb3ff",
              "IPY_MODEL_efc8f191a76149a3a20199d93e367f3b"
            ],
            "layout": "IPY_MODEL_1e384601d23c4acb918b9ee98c35507e"
          }
        },
        "1012c8d8604345ebbd481da20003a0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d0351792ca402481eba68e5f3a5e0b",
            "placeholder": "​",
            "style": "IPY_MODEL_814d96fed16a4b82bc2225d0f761ef4a",
            "value": "Generating embeddings: 100%"
          }
        },
        "07fd0784cd354676b0b24752bcffb3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afca0df6fc8546d9b9a3ca46ff5a70d7",
            "max": 1181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80f81c806e404045a059be2c9f705245",
            "value": 1181
          }
        },
        "efc8f191a76149a3a20199d93e367f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb658f259eb64d22abfbe5c8c5608eae",
            "placeholder": "​",
            "style": "IPY_MODEL_0a9a09dc5839400f82ead38e046d2068",
            "value": " 1181/1181 [00:17&lt;00:00, 72.32it/s]"
          }
        },
        "1e384601d23c4acb918b9ee98c35507e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d0351792ca402481eba68e5f3a5e0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "814d96fed16a4b82bc2225d0f761ef4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afca0df6fc8546d9b9a3ca46ff5a70d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f81c806e404045a059be2c9f705245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb658f259eb64d22abfbe5c8c5608eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9a09dc5839400f82ead38e046d2068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}