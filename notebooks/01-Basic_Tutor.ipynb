{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ai-tutor-rag-system/blob/main/notebooks/01-Basic_Tutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMXyyXD0xix9"
      },
      "source": [
        "# Install Packages and Setup Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4Q0N2omkAoZ",
        "outputId": "703fe996-2acf-4e90-92c1-252041ba7d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai==1.30.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xxK7EAAvr2aT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the \"OPENAI_API_KEY\" in the Python environment. Will be used by OpenAI client later.\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_OPENAI_KEY>\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68RbStS-xpbL"
      },
      "source": [
        "# Load the API client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "La8hdWqJkFkh"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Defining the \"client\" object that enables\n",
        "# us to connect to OpenAI API endpoints.\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC-sa_uv6J2C"
      },
      "source": [
        "# Query the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7JRrn0uIsBfg"
      },
      "outputs": [],
      "source": [
        "# Define two questions: 1) Related to AI, 2) Unrelated topic.\n",
        "# These questions will be used to evaluate model's performance.\n",
        "QUESTION_AI = \"List a number of famous artificial intelligence frameworks?\"\n",
        "QUESTION_NOT_AI = \"What is the name of the highest mountain in the world and its height?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CcP26IauuBuV"
      },
      "outputs": [],
      "source": [
        "# Defining a function to answer a question using \"gpt-3.5-turbo\" model.\n",
        "def ask_ai_tutor(question):\n",
        "    try:\n",
        "        # Formulating the system prompt and condition the model to answer only AI-related questions.\n",
        "        system_prompt = (\n",
        "            \"You are an AI tutor specialized in answering artificial intelligence-related questions. \"\n",
        "            \"Only answer AI-related question, else say that you cannot answer this question.\"\n",
        "        )\n",
        "\n",
        "        # Create a user prompt with the user's question\n",
        "        prompt = f\"Please provide an informative and accurate answer to the following question.\\nQuestion: {question}\\nAnswer:\"\n",
        "\n",
        "        # Call the OpenAI API\n",
        "        response = client.chat.completions.create(\n",
        "                model='gpt-3.5-turbo',\n",
        "                temperature=1,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": system_prompt},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        # Return the AI's response\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_dbwURpufR7",
        "outputId": "3cd84fb9-fe6f-4561-e9ee-ed606a983629"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some famous artificial intelligence frameworks include TensorFlow, PyTorch, Keras, Microsoft Cognitive Toolkit (CNTK), and Apache MXNet.\n"
          ]
        }
      ],
      "source": [
        "# Ask the AI-related question.\n",
        "RES_AI = ask_ai_tutor( QUESTION_AI )\n",
        "print( RES_AI )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37YuVJQquhpN",
        "outputId": "4550c44d-2150-4cca-f23e-c89ea43e2040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm sorry, but I cannot answer this question as it is not related to artificial intelligence. If you have any AI-related questions, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "# Ask the unrelated question.\n",
        "RES_NOT_AI = ask_ai_tutor( QUESTION_NOT_AI )\n",
        "print( RES_NOT_AI )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRBgk6WToIK0"
      },
      "source": [
        "# History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_6GN2XsoEyM",
        "outputId": "3e66a833-a552-4bcc-9808-7b9f6b539310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The first suggested AI framework in the list provided earlier is TensorFlow. TensorFlow is an open-source machine learning library developed by Google that has become popular for its flexibility, scalability, and extensive support for deep learning algorithms. It allows users to build and train machine learning models efficiently, with various tools and resources available to aid in the development process. TensorFlow is widely used in research and industry for tasks such as image recognition, natural language processing, and reinforcement learning.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(\n",
        "              model='gpt-3.5-turbo',\n",
        "              temperature=1,\n",
        "              messages=[\n",
        "                  {\"role\": \"system\", \"content\": \"You are an AI tutor specialized in answering artificial intelligence-related questions. Only answer AI-related question, else say that you cannot answer this question.\"},\n",
        "                  {\"role\": \"user\", \"content\": \"Please provide an informative and accurate answer to the following question.\\nQuestion: List a number of famous artificial intelligence frameworks?\\nAnswer:\"},\n",
        "                  {\"role\": \"assistant\", \"content\": RES_AI},\n",
        "                  {\"role\": \"user\", \"content\": \"Please provide an informative and accurate answer to the following question.\\nQuestion: What is the name of the highest mountain in the world and its height?\\nAnswer:\"},\n",
        "                  {\"role\": \"assistant\", \"content\": RES_NOT_AI},\n",
        "                  {\"role\": \"user\", \"content\": \"Please provide an informative and accurate answer to the following question.\\nQuestion: Can you write a summary of the first suggested AI framework in the first question?\\nAnswer:\"}\n",
        "              ]\n",
        "            )\n",
        "\n",
        "print( response.choices[0].message.content.strip() )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOUuEM41HPKH6uCJFqocvSD",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
