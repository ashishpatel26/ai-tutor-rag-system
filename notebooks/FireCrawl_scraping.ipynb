{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install the requirements"
      ],
      "metadata": {
        "id": "z9h3lrtQRhYv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKBQrqNsjrLB",
        "outputId": "0c4fb7c8-6960-45ea-ec65-5b3849ef0337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.9/37.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for spider-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "pip install -q llama-index==0.10.30 openai==1.12.0 tiktoken==0.6.0 llama-index-readers-web firecrawl-py==1.2.3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SET THE ENVIRONMENT VARIABLES"
      ],
      "metadata": {
        "id": "TKh_dKV6Rm9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\"\n",
        "FIRECRAWL_API_KEY = \"FIRECRAWL_API_KEY\""
      ],
      "metadata": {
        "id": "QZgBdtZRJfze"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCRAPE WITH FIRECRAWL"
      ],
      "metadata": {
        "id": "tiBy7Q74Vkt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORT THE FIRECRAWL WEBREADER\n",
        "\n",
        "Firecrawl allows you to turn entire websites into LLM-ready markdown\n",
        "\n",
        "Get the API key here\n",
        "https://www.firecrawl.dev/app/api-keys"
      ],
      "metadata": {
        "id": "GQP8VA_gRr2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.web import FireCrawlWebReader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuLILEoNj2lG",
        "outputId": "293ad6c5-4859-46bb-e25a-b588c014867a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /usr/local/lib/python3.10/dist-\n",
            "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# using firecrawl to crawl a website\n",
        "firecrawl_reader = FireCrawlWebReader(\n",
        "    api_key=FIRECRAWL_API_KEY,  # Replace with your actual API key from https://www.firecrawl.dev/\n",
        "    mode=\"scrape\",\n",
        ")\n",
        "\n",
        "# Load documents from a single page URL\n",
        "documents = firecrawl_reader.load_data(url=\"https://towardsai.net/\")"
      ],
      "metadata": {
        "id": "x-ls9L0QWC3S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "zL1BOBWhWrfe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = query_engine.query(\"What is towards AI aim?\")\n",
        "\n",
        "print(res.response)\n",
        "\n",
        "print(\"-----------------\")\n",
        "# Show the retrieved nodes\n",
        "for src in res.source_nodes:\n",
        "  print(\"Node ID\\t\", src.node_id)\n",
        "  print(\"Title\\t\", src.metadata['title'])\n",
        "  print(\"URL\\t\", src.metadata['sourceURL'])\n",
        "  print(\"Score\\t\", src.score)\n",
        "  print(\"Description\\t\", src.metadata.get(\"description\"))\n",
        "  print(\"-_\"*20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV4Fg-haWspw",
        "outputId": "04642e46-1f4f-4e89-972a-326cca793f34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Towards AI aims to make AI and machine learning accessible to all by providing courses, blogs, tutorials, books, newsletters, and a community platform.\n",
            "-----------------\n",
            "Node ID\t fd7ec7d6-aaf7-4350-b1fd-7bb9f256abf1\n",
            "Title\t Towards AI\n",
            "URL\t https://towardsai.net/\n",
            "Score\t 0.8927276434780216\n",
            "Description\t Towards AI is an online publication, which focuses on sharing high-quality publications, news, articles, and stories on AI and technology related topics.\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
            "Node ID\t e8b70bef-9f08-45e9-bb0b-c6177f711740\n",
            "Title\t Towards AI\n",
            "URL\t https://towardsai.net/\n",
            "Score\t 0.8873490308374337\n",
            "Description\t Towards AI is an online publication, which focuses on sharing high-quality publications, news, articles, and stories on AI and technology related topics.\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CRAWL A WEBSITE"
      ],
      "metadata": {
        "id": "lRjJrc7VVaNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load The CSV\n",
        "\n",
        "CSV contains the list of tools and url of the page which we use to get information about the tool."
      ],
      "metadata": {
        "id": "Uj6dqla8SEwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "\n",
        "# Google Sheets file URL (CSV export link)\n",
        "url = 'https://docs.google.com/spreadsheets/d/1gHB-aQJGt9Nl3cyOP2GorAkBI_Us2AqkYnfqrmejStc/export?format=csv'\n",
        "\n",
        "# Send a GET request to fetch the CSV file\n",
        "response = requests.get(url)\n",
        "\n",
        "response_list = []\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Decode the content to a string\n",
        "    content = response.content.decode('utf-8')\n",
        "\n",
        "    # Use the csv.DictReader to read the content as a dictionary\n",
        "    csv_reader = csv.DictReader(content.splitlines(), delimiter=',')\n",
        "    response_list = [row for row in csv_reader]\n",
        "else:\n",
        "    print(f\"Failed to retrieve the file: {response.status_code}\")\n"
      ],
      "metadata": {
        "id": "aWTgax6zZpLx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "website_list = response_list[3:5] # crawling 2 website for demo"
      ],
      "metadata": {
        "id": "atFrRz4MgmaR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "print(\"CSV data\")\n",
        "pprint.pprint(website_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHWjBFSQMWZk",
        "outputId": "f589564e-5cc3-4031-8481-55b3843d9380"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV data\n",
            "[{'': '',\n",
            "  'Category': 'Database',\n",
            "  'Description': 'Persistent key-value store for fast storage environments',\n",
            "  'Is a direct URL company /tool website?': 'Yes',\n",
            "  'Name': 'RocksDB',\n",
            "  'Tool Type': 'Database',\n",
            "  'URL': 'https://rocksdb.org/'},\n",
            " {'': '',\n",
            "  'Category': 'Database',\n",
            "  'Description': 'Document-oriented NoSQL database',\n",
            "  'Is a direct URL company /tool website?': 'Yes',\n",
            "  'Name': 'MongoDB',\n",
            "  'Tool Type': 'Database',\n",
            "  'URL': 'https://www.mongodb.com/lp/cloud/atlas/try4?utm_source=google&utm_campaign=search_gs_pl_evergreen_atlas_core_prosp-brand_gic-null_apac-ph_ps-all_desktop_eng_lead&utm_term=mongodb&utm_medium=cpc_paid_search&utm_ad=e&utm_ad_campaign_id=12212624359&adgroup=115749710543&cq_cmp=12212624359&gad_source=1&gclid=CjwKCAjw5Ky1BhAgEiwA5jGujmI0-QgV5DXTwtMUH6mJur8nIVAxkMMSoNHvp_519fBdvutBriWLHxoCe8AQAvD_BwE'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the Firecrawl"
      ],
      "metadata": {
        "id": "S1SO6txzTBT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from firecrawl import FirecrawlApp\n",
        "app = FirecrawlApp(api_key=FIRECRAWL_API_KEY)"
      ],
      "metadata": {
        "id": "o8GphTUy7IS_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Crawl websites and handle responses\n",
        "url_response = {}\n",
        "crawl_per_min = 1  # Max crawl per minute\n",
        "\n",
        "# Track crawls\n",
        "crawled_websites = 0\n",
        "scraped_pages = 0\n",
        "\n",
        "for i, website_dict in enumerate(website_list):\n",
        "    url = website_dict.get('URL')\n",
        "    print(f\"Crawling: {url}\")\n",
        "\n",
        "    try:\n",
        "        response = app.crawl_url(\n",
        "            url,\n",
        "            params={\n",
        "                'limit': 10,  # Limit pages to scrape per site.\n",
        "                'scrapeOptions': {'formats': ['markdown', 'html']}\n",
        "            }\n",
        "        )\n",
        "        crawled_websites += 1\n",
        "\n",
        "    except Exception as exc:\n",
        "        print(f\"Failed to fetch {url} -> {exc}\")\n",
        "        continue\n",
        "\n",
        "    # Store the scraped data and associated info in the response dict\n",
        "    url_response[url] = {\n",
        "        \"scraped_data\": response.get(\"data\"),\n",
        "        \"csv_data\": website_dict\n",
        "    }\n",
        "\n",
        "    # Pause to comply with crawl per minute limit for free version its 1 crawl per minute\n",
        "    if i!=len(website_list) and (i + 1) % crawl_per_min == 0:\n",
        "        print(\"Pausing for 1 minute to comply with crawl limit...\")\n",
        "        time.sleep(60)  # Pause for 1 minute after every crawl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-G8fB6KyGP7",
        "outputId": "a06cfbb4-a5c0-4a49-8c8e-254943b34c52"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crawling: https://rocksdb.org/\n",
            "Pausing for 1 minute to comply with crawl limit...\n",
            "Crawling: https://www.mongodb.com/lp/cloud/atlas/try4?utm_source=google&utm_campaign=search_gs_pl_evergreen_atlas_core_prosp-brand_gic-null_apac-ph_ps-all_desktop_eng_lead&utm_term=mongodb&utm_medium=cpc_paid_search&utm_ad=e&utm_ad_campaign_id=12212624359&adgroup=115749710543&cq_cmp=12212624359&gad_source=1&gclid=CjwKCAjw5Ky1BhAgEiwA5jGujmI0-QgV5DXTwtMUH6mJur8nIVAxkMMSoNHvp_519fBdvutBriWLHxoCe8AQAvD_BwE\n",
            "Pausing for 1 minute to comply with crawl limit...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create  llamaindex documents from the scraped content"
      ],
      "metadata": {
        "id": "gwu6VIMvTKp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document\n",
        "documents = []\n",
        "\n",
        "for _, scraped_content in url_response.items():\n",
        "    csv_data = scraped_content.get(\"csv_data\")\n",
        "    scraped_results = scraped_content.get(\"scraped_data\")\n",
        "\n",
        "    for scraped_site_dict in scraped_results:\n",
        "        for result in scraped_results:\n",
        "            markdown_content = result.get(\"markdown\")\n",
        "            title = result.get(\"metadata\").get(\"title\")\n",
        "            url = result.get(\"metadata\").get(\"sourceURL\")\n",
        "            documents.append(\n",
        "                Document(\n",
        "                    text=markdown_content,\n",
        "                    metadata={\n",
        "                        \"title\": title,\n",
        "                        \"url\": url,\n",
        "                        \"description\": csv_data.get(\"Description\"),\n",
        "                        \"category\": csv_data.get(\"Category\")\n",
        "                    }\n",
        "                )\n",
        "            )\n"
      ],
      "metadata": {
        "id": "fHSEWg7FBdSS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create The RAG Pipeline."
      ],
      "metadata": {
        "id": "uwtRhcpQT294"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4o-mini\")\n",
        "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
        "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=30)"
      ],
      "metadata": {
        "id": "iDOgwesPI-Kq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.text_splitter = text_splitter"
      ],
      "metadata": {
        "id": "R8Oi4MiJJQii"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "61ZLk2GoJ4VH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "def display_response(response):\n",
        "    display(Markdown(f\"<b>{response}</b>\"))"
      ],
      "metadata": {
        "id": "R1ImxmsoUNVo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = query_engine.query(\"I want to use key value store which is the best db?\")\n",
        "display_response(res)\n",
        "\n",
        "print(\"-----------------\")\n",
        "# Show the retrieved nodes\n",
        "for src in res.source_nodes:\n",
        "  print(\"Node ID\\t\", src.node_id)\n",
        "  print(\"Title\\t\", src.metadata['title'])\n",
        "  print(\"URL\\t\", src.metadata['url'])\n",
        "  print(\"Score\\t\", src.score)\n",
        "  print(\"Description\\t\", src.metadata.get(\"description\"))\n",
        "  print(\"Category\\t\", src.metadata.get(\"category\"))\n",
        "  print(\"-_\"*20)\n",
        "\n",
        "\n",
        "res = query_engine.query(\"Compare the best No sql dbs?\")\n",
        "\n",
        "display_response(res.response)\n",
        "\n",
        "print(\"-----------------\")\n",
        "# Show the retrieved nodes\n",
        "for src in res.source_nodes:\n",
        "  print(\"Node ID\\t\", src.node_id)\n",
        "  print(\"Title\\t\", src.metadata['title'])\n",
        "  print(\"URL\\t\", src.metadata['url'])\n",
        "  print(\"Score\\t\", src.score)\n",
        "  print(\"Description\\t\", src.metadata.get(\"description\"))\n",
        "  print(\"Category\\t\", src.metadata.get(\"category\"))\n",
        "  print(\"-_\"*20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "pcFcFgCvJ7Y8",
        "outputId": "84449163-47ed-4d15-a080-2a18600e5bc4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>RocksDB is a high-performance, adaptable key-value store optimized for fast storage environments. It is designed for maximum performance using a log structured database engine written in C++. RocksDB can handle a variety of workloads, from database storage engines to application data caching, making it a versatile option for different data needs.</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "Node ID\t d8913762-56d9-46e7-be6a-1472e8af426d\n",
            "Title\t RocksDB | A persistent key-value store | RocksDB\n",
            "URL\t http://rocksdb.org/\n",
            "Score\t 0.49236056175089676\n",
            "Description\t Persistent key-value store for fast storage environments\n",
            "Category\t Database\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<b>MongoDB Atlas and RocksDB are both popular NoSQL databases, each with its own strengths. MongoDB Atlas is a cloud-based document-oriented database that offers a fully managed service with features like secure default settings, multi-cloud support, and a document model that aligns well with application code. On the other hand, RocksDB is a persistent key-value store known for its high performance in fast storage environments, particularly excelling in terms of low write amplification and write performance. Both databases cater to different use cases and have unique advantages based on the specific requirements of the application or workload.</b>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "Node ID\t 0e8a82be-ca4d-4526-b45b-7b78d2323d42\n",
            "Title\t MongoDB Atlas: Cloud Document Database | MongoDB\n",
            "URL\t https://www.mongodb.com/lp/cloud/atlas/try4?utm_source=google&utm_campaign=search_gs_pl_evergreen_atlas_core_prosp-brand_gic-null_apac-ph_ps-all_desktop_eng_lead&utm_term=mongodb&utm_medium=cpc_paid_search&utm_ad=e&utm_ad_campaign_id=12212624359&adgroup=115749710543&cq_cmp=12212624359&gad_source=1&gclid=CjwKCAjw5Ky1BhAgEiwA5jGujmI0-QgV5DXTwtMUH6mJur8nIVAxkMMSoNHvp_519fBdvutBriWLHxoCe8AQAvD_BwE\n",
            "Score\t 0.46048151159026907\n",
            "Description\t Document-oriented NoSQL database\n",
            "Category\t Database\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
            "Node ID\t 4f6405f8-eec6-482b-b4d8-d9cc76e436a3\n",
            "Title\t Blog | RocksDB\n",
            "URL\t https://rocksdb.org/blog/\n",
            "Score\t 0.39345216447105164\n",
            "Description\t Persistent key-value store for fast storage environments\n",
            "Category\t Database\n",
            "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZW4aivJYQ5I"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}
