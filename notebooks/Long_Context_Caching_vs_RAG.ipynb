{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9bpz99INAc1"
   },
   "source": [
    "# Install Packages and Setup Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "BeuFJKlj9jKz",
    "outputId": "3e024341-be6d-4f1f-e39a-1a491fa8df34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/150.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.1/679.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.0/189.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q google-generativeai==0.5.4 llama-index-llms-gemini==0.3.7 llama-index openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWholrWlt2OQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Set the following API Keys in the Python environment. Will be used later.\n",
    "# We use OpenAI for the embedding model and Gemini-1.5-flash as our LLM.\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_OPENAI_KEY>\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
    "\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = userdata.get('Google_api_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5eV5EnvNCMM"
   },
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-7mRQ-mNJlm"
   },
   "source": [
    "## Download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PsdOdMUNmEi"
   },
   "source": [
    "The dataset includes a subset of the documentation from the Llama-index library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ImRCP7pACaI",
    "outputId": "0b311670-2ad6-445c-ec01-d92e37d048a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   115  100   115    0     0    472      0 --:--:-- --:--:-- --:--:--   473\n",
      "100  570k  100  570k    0     0   922k      0 --:--:-- --:--:-- --:--:--  922k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./llama_index_150k.jsonl https://huggingface.co/datasets/towardsai-buster/llama-index-docs/raw/main/llama_index_data_150k.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZZLK_wyEc-L"
   },
   "source": [
    "## Read File and create LlamaIndex Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miUqycqAEfr7",
    "outputId": "b9314b1e-a00f-4f6f-957f-ecba1a14dd9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 56\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "import json\n",
    "\n",
    "\n",
    "def create_docs(input_file: str) -> list[Document]:\n",
    "    documents = []\n",
    "    with open(input_file, \"r\") as f:\n",
    "        for idx, line in enumerate(f, start=1):\n",
    "\n",
    "          data = json.loads(line)\n",
    "\n",
    "          required_keys = {\"doc_id\", \"content\", \"url\", \"name\", \"tokens\", \"source\"}\n",
    "          if not required_keys.issubset(data):\n",
    "              print(f\"Missing keys in line {idx}: {required_keys - set(data)}\")\n",
    "              continue\n",
    "\n",
    "          documents.append(\n",
    "              Document(\n",
    "                  doc_id=data[\"doc_id\"],\n",
    "                  text=data[\"content\"],\n",
    "                  metadata={  # type: ignore\n",
    "                      \"url\": data[\"url\"],\n",
    "                      \"title\": data[\"name\"],\n",
    "                      \"tokens\": data[\"tokens\"],\n",
    "                      \"source\": data[\"source\"],\n",
    "                  },\n",
    "                  excluded_llm_metadata_keys=[\n",
    "                      \"title\",\n",
    "                      \"tokens\",\n",
    "                      \"source\",\n",
    "                  ],\n",
    "                  excluded_embed_metadata_keys=[\n",
    "                      \"url\",\n",
    "                      \"tokens\",\n",
    "                      \"source\",\n",
    "                  ],\n",
    "              )\n",
    "          )\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Convert the texts to Document objects.\n",
    "documents = create_docs(\"llama_index_150k.jsonl\")\n",
    "print(f\"Number of documents: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f86yksB9K571"
   },
   "source": [
    "# Generate Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "5351c27bdd65486e854d6e27e9944ab5",
      "a6ee19a13fd5465486521cdfe473ae06",
      "a824583a1b0e46299e65c21779a6b326",
      "19073fe17e944f84a9c8c21df9d1e921",
      "27de509db8094b1a8ada3b5cd87e854b",
      "360e5d1d99ef4787bfa1f4f0277fd90d",
      "315c46645dd9474d8779e8c452847bda",
      "a513e5cb3a684e698c90f91072b25481",
      "fd83e928bf7541ae8f7dd1cb7de400be",
      "5c234d72ab5c4cd7bb297e4e97c20a39",
      "5399085042a14bd5adb9ec2b4b5c7137",
      "01b4fdf3e4cd4c95b2b8a339029094cf",
      "a66940a7edc44883885cbc8cdbc29884",
      "2ee3ed8c28fc4b749296c7452ec05b66",
      "0dc0c3f21a054876a4379854517f62bc",
      "70aa2d7073cd47e9b704d809c5b8e8a2",
      "cb33b656e08f4292a3a3e3aac6079817",
      "5b57ce60a94b4af2800754bff85281cf",
      "42d93b888bae475da468d70036f3fa5c",
      "f5c4c584bad14ae3b203c6322b4ffe59",
      "1b036779f62941bbb4d8bb95d0e8c47e",
      "088a9cf5767448e2826c0b20227ae8ad"
     ]
    },
    "id": "Bsa7Q-DoNWBk",
    "outputId": "e88492dc-750f-4e98-c17c-d74dabbaa71c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5351c27bdd65486e854d6e27e9944ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b4fdf3e4cd4c95b2b8a339029094cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "\n",
    "# Build index / generate embeddings using OpenAI embedding model\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=OpenAIEmbedding(model=\"text-embedding-3-small\"),\n",
    "    transformations=[SentenceSplitter(chunk_size=512, chunk_overlap=128)],\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DoUxd8KK--Q"
   },
   "source": [
    "# Query Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUaNH97dEfh9"
   },
   "outputs": [],
   "source": [
    "# Define a query engine that is responsible for retrieving related pieces of text,\n",
    "# and using a LLM to formulate the final answer.\n",
    "\n",
    "from llama_index.llms.gemini import Gemini\n",
    "\n",
    "llm = Gemini(model=\"models/gemini-1.5-flash\", temperature=1, max_tokens=1000)\n",
    "\n",
    "query_engine = index.as_query_engine(llm=llm, similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "id": "KHK4V_GRR6ZG",
    "outputId": "4daefcea-4e8a-45b6-b6f8-c16733c71e2c"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To create a query engine, first create an index and then use the `as_query_engine()` method. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  3.605879545211792\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "response = query_engine.query(\"How to setup a query engine in code?\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(Markdown(response.response))\n",
    "print(\"time taken: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "id": "S-BmyTBbNd9y",
    "outputId": "94f761eb-fb42-4005-9010-99b579aca6c6"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You can create an agent by using the `ReActAgent` class.  First, you should define a list of tools that the agent can use. Next, create an `OpenAI` object to act as the language model, specifying a model such as \"gpt-3.5-turbo\" with a temperature of 0. Finally, initialize the `ReActAgent` with the list of tools and the LLM, setting the `verbose` parameter to `True` to see the agent's thought process. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  2.861610174179077\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "response = query_engine.query(\"How to setup an agent in code?\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "display(Markdown(response.response))\n",
    "print(\"time taken: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_55vnPoSlID"
   },
   "source": [
    "# Setup Long Context Caching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBSZTxjfSlID"
   },
   "source": [
    "For this section, we will be using the Gemini API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You might encounter dependency issues, which may require restarting the session. Please reinstall google-generativeai to the latest version. To use long-context caching in google-generativeai, ensure you have version 0.7.2 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-xVY9mXk-eN",
    "outputId": "14ec1a5b-169a-461e-bf2a-e96b04f9ba66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.0/189.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q google-generativeai==0.8.3 llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPm3PFcy3SKp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR_API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHlXwVnJ3V8V",
    "outputId": "bc8aab5a-d174-4e7e-bcf7-c76cdf2024fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   115  100   115    0     0    153      0 --:--:-- --:--:-- --:--:--   153\n",
      "100  570k  100  570k    0     0   340k      0  0:00:01  0:00:01 --:--:--  340k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o ./llama_index_150k.jsonl https://huggingface.co/datasets/towardsai-buster/llama-index-docs/raw/main/llama_index_data_150k.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGuvt0-N3WsP",
    "outputId": "17e30210-fcca-411f-8efb-69638dfee16e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 56\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from llama_index.core import Document\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def create_docs(input_file: str) -> list[Document]:\n",
    "    documents = []\n",
    "    with open(input_file, \"r\") as f:\n",
    "        for idx, line in enumerate(f, start=1):\n",
    "\n",
    "          data = json.loads(line)\n",
    "\n",
    "          required_keys = {\"doc_id\", \"content\", \"url\", \"name\", \"tokens\", \"source\"}\n",
    "          if not required_keys.issubset(data):\n",
    "              print(f\"Missing keys in line {idx}: {required_keys - set(data)}\")\n",
    "              continue\n",
    "\n",
    "          documents.append(\n",
    "              Document(\n",
    "                  doc_id=data[\"doc_id\"],\n",
    "                  text=data[\"content\"],\n",
    "                  metadata={  # type: ignore\n",
    "                      \"url\": data[\"url\"],\n",
    "                      \"title\": data[\"name\"],\n",
    "                      \"tokens\": data[\"tokens\"],\n",
    "                      \"source\": data[\"source\"],\n",
    "                  },\n",
    "                  excluded_llm_metadata_keys=[\n",
    "                      \"title\",\n",
    "                      \"tokens\",\n",
    "                      \"source\",\n",
    "                  ],\n",
    "                  excluded_embed_metadata_keys=[\n",
    "                      \"url\",\n",
    "                      \"tokens\",\n",
    "                      \"source\",\n",
    "                  ],\n",
    "              )\n",
    "          )\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Convert the texts to Document objects.\n",
    "documents = create_docs(\"llama_index_150k.jsonl\")\n",
    "print(f\"Number of documents: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eGIFfZrBSlID"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import caching\n",
    "from google.generativeai import GenerationConfig\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex4X8BE3SlIE"
   },
   "source": [
    "Convert the jsonl file to a text file for the Gemini API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcL6M1VpSlIE",
    "outputId": "4f083d4b-00b3-41ca-c833-b123065c53d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents saved to llama_index_contents.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def create_text_file(input_file: str, output_file: str) -> None:\n",
    "    with open(input_file, \"r\") as f, open(output_file, \"w\") as out:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            out.write(data[\"content\"] + \"\\n\\n\")  # Add two newlines between documents\n",
    "\n",
    "    print(f\"Contents saved to {output_file}\")\n",
    "\n",
    "\n",
    "create_text_file(\"llama_index_150k.jsonl\", \"llama_index_contents.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "l2S4vl3ySlIE"
   },
   "outputs": [],
   "source": [
    "document = genai.upload_file(path=\"llama_index_contents.txt\")\n",
    "model_name = \"gemini-1.5-flash-001\"\n",
    "\n",
    "cache = genai.caching.CachedContent.create(\n",
    "    model=model_name,\n",
    "    system_instruction=\"You answer questions about the LlamaIndex framework.\",\n",
    "    contents=[document],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GsPYVW6hSlIF"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "model = genai.GenerativeModel.from_cached_content(cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86jV_ZiIFBKa"
   },
   "source": [
    "## Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "id": "DtSYddEjEnLa",
    "outputId": "9427c8a6-90a8-47f3-cbd9-199a15dace4a"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "LlamaParse is a state-of-the-art document parsing solution developed by LlamaIndex. It is a powerful tool for extracting structured information from unstructured documents like PDFs, Word files, and HTML pages. \n",
       "\n",
       "Here's a breakdown of LlamaParse and how to set it up:\n",
       "\n",
       "**What is LlamaParse?**\n",
       "\n",
       "* **Document Understanding:** LlamaParse goes beyond simple text extraction. It leverages advanced techniques like natural language processing (NLP) and machine learning to understand the document's structure, identify key entities, and extract relevant information. \n",
       "* **Structured Data Extraction:** LlamaParse aims to convert unstructured documents into structured data, making it easier to process, analyze, and query. This can include things like tables, lists, headings, and even text formatting.\n",
       "* **Data Integration:** The extracted structured data from LlamaParse can be easily integrated into other systems or databases for further analysis or use in LLM applications.\n",
       "\n",
       "**How to Setup LlamaParse**\n",
       "\n",
       "LlamaParse is currently offered as a managed service through **LlamaCloud**. You can use it either as a self-hosted solution or utilize their hosted service.\n",
       "\n",
       "**1. Sign Up for LlamaCloud:**\n",
       "   - Visit the LlamaCloud website: [https://cloud.llamaindex.ai/](https://cloud.llamaindex.ai/)\n",
       "   - Sign up for a free account. You get a certain number of free parsing pages per day.\n",
       "\n",
       "**2. Generate API Key:**\n",
       "   - Once you are logged in, navigate to the \"API Keys\" section.\n",
       "   - Generate a new API key.\n",
       "\n",
       "**3. Install the LlamaParse library:**\n",
       "   - Use pip to install the LlamaParse library:\n",
       "     ```bash\n",
       "     pip install llama-parse\n",
       "     ```\n",
       "\n",
       "**4. Usage Example:**\n",
       "\n",
       "   ```python\n",
       "   from llama_parse import LlamaParse\n",
       "\n",
       "   # Replace with your LlamaCloud API key\n",
       "   os.environ[\"LLAMA_CLOUD_API_KEY\"] = \"your_api_key\"\n",
       "\n",
       "   # Load a PDF file\n",
       "   documents = LlamaParse(result_type=\"markdown\").load_data(\n",
       "       \"./your_pdf_file.pdf\"\n",
       "   )\n",
       "\n",
       "   # Process the extracted data\n",
       "   for document in documents:\n",
       "       print(document.text)\n",
       "   ```\n",
       "\n",
       "**Key Points:**\n",
       "\n",
       "* **Result Type:** LlamaParse offers various `result_type` options:\n",
       "    - `markdown`: Provides a formatted markdown version of the document.\n",
       "    - `json`:  Returns a JSON representation of the structured data.\n",
       "    - `text`: Extracts the plain text content of the document.\n",
       "    - `structured`:  Provides a complex structured representation of the document. \n",
       "* **Customization:** You can customize LlamaParse to tailor its behavior using various parameters like `result_type`, `parser`, `table_parser`, and more.  Refer to the LlamaParse [documentation](https://docs.cloud.llamaindex.ai/llamaparse/getting_started) for a complete overview.\n",
       "\n",
       "Let me know if you have any more questions about LlamaParse.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  10.533137798309326\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "response = model.generate_content(\n",
    "    \"What is LlamaParse, How to setup?\",\n",
    "    generation_config=GenerationConfig(max_output_tokens=1000),\n",
    ")\n",
    "end = time.time()\n",
    "display(Markdown(response.text))\n",
    "print(\"time taken: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2Rq1syJEsze",
    "outputId": "5bdf3c9a-af19-4526-fc52-23c04d53c4b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_token_count: 212097\n",
       "cached_content_token_count: 212087\n",
       "candidates_token_count: 646\n",
       "total_token_count: 212743"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i_Pf7Y5EVi5"
   },
   "source": [
    "## First token response time in Straming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 64
    },
    "id": "UyTXWVaREXYC",
    "outputId": "accb4fb6-03e6-4d71-fa49-6beb9e98eb07"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken:  5.295310974121094\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "response = model.generate_content(\n",
    "    \"How to setup a Router query engine?\",\n",
    "    generation_config=GenerationConfig(max_output_tokens=1),\n",
    ")\n",
    "end = time.time()\n",
    "display(Markdown(response.text))\n",
    "print(\"time taken: \", end - start)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01b4fdf3e4cd4c95b2b8a339029094cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a66940a7edc44883885cbc8cdbc29884",
       "IPY_MODEL_2ee3ed8c28fc4b749296c7452ec05b66",
       "IPY_MODEL_0dc0c3f21a054876a4379854517f62bc"
      ],
      "layout": "IPY_MODEL_70aa2d7073cd47e9b704d809c5b8e8a2"
     }
    },
    "088a9cf5767448e2826c0b20227ae8ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0dc0c3f21a054876a4379854517f62bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b036779f62941bbb4d8bb95d0e8c47e",
      "placeholder": "​",
      "style": "IPY_MODEL_088a9cf5767448e2826c0b20227ae8ad",
      "value": " 447/447 [00:06&lt;00:00, 62.11it/s]"
     }
    },
    "19073fe17e944f84a9c8c21df9d1e921": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c234d72ab5c4cd7bb297e4e97c20a39",
      "placeholder": "​",
      "style": "IPY_MODEL_5399085042a14bd5adb9ec2b4b5c7137",
      "value": " 56/56 [00:00&lt;00:00, 52.51it/s]"
     }
    },
    "1b036779f62941bbb4d8bb95d0e8c47e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27de509db8094b1a8ada3b5cd87e854b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ee3ed8c28fc4b749296c7452ec05b66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42d93b888bae475da468d70036f3fa5c",
      "max": 447,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5c4c584bad14ae3b203c6322b4ffe59",
      "value": 447
     }
    },
    "315c46645dd9474d8779e8c452847bda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "360e5d1d99ef4787bfa1f4f0277fd90d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42d93b888bae475da468d70036f3fa5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5351c27bdd65486e854d6e27e9944ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6ee19a13fd5465486521cdfe473ae06",
       "IPY_MODEL_a824583a1b0e46299e65c21779a6b326",
       "IPY_MODEL_19073fe17e944f84a9c8c21df9d1e921"
      ],
      "layout": "IPY_MODEL_27de509db8094b1a8ada3b5cd87e854b"
     }
    },
    "5399085042a14bd5adb9ec2b4b5c7137": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b57ce60a94b4af2800754bff85281cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c234d72ab5c4cd7bb297e4e97c20a39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70aa2d7073cd47e9b704d809c5b8e8a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a513e5cb3a684e698c90f91072b25481": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a66940a7edc44883885cbc8cdbc29884": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb33b656e08f4292a3a3e3aac6079817",
      "placeholder": "​",
      "style": "IPY_MODEL_5b57ce60a94b4af2800754bff85281cf",
      "value": "Generating embeddings: 100%"
     }
    },
    "a6ee19a13fd5465486521cdfe473ae06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_360e5d1d99ef4787bfa1f4f0277fd90d",
      "placeholder": "​",
      "style": "IPY_MODEL_315c46645dd9474d8779e8c452847bda",
      "value": "Parsing nodes: 100%"
     }
    },
    "a824583a1b0e46299e65c21779a6b326": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a513e5cb3a684e698c90f91072b25481",
      "max": 56,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd83e928bf7541ae8f7dd1cb7de400be",
      "value": 56
     }
    },
    "cb33b656e08f4292a3a3e3aac6079817": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5c4c584bad14ae3b203c6322b4ffe59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd83e928bf7541ae8f7dd1cb7de400be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
