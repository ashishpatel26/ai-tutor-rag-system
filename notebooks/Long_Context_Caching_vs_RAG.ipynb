{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ai-tutor-rag-system/blob/main/notebooks/Long_Context_Caching_vs_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9bpz99INAc1"
      },
      "source": [
        "# Install Packages and Setup Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BeuFJKlj9jKz",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai==0.5.4 llama-index-llms-gemini==0.3.7 llama-index openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CWholrWlt2OQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Set the following API Keys in the Python environment. Will be used later.\n",
        "# We use OpenAI for the embedding model and Gemini-1.5-flash as our LLM.\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_OPENAI_KEY>\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
        "\n",
        "\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = userdata.get('Google_api_key')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5eV5EnvNCMM"
      },
      "source": [
        "# Load Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-7mRQ-mNJlm"
      },
      "source": [
        "## Download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PsdOdMUNmEi"
      },
      "source": [
        "The dataset includes a subset of the documentation from the Llama-index library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ImRCP7pACaI",
        "outputId": "624f3c59-77a7-4342-980b-0e0acf775a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   115  100   115    0     0    730      0 --:--:-- --:--:-- --:--:--   732\n",
            "100  570k  100  570k    0     0  2087k      0 --:--:-- --:--:-- --:--:-- 2087k\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o ./llama_index_150k.jsonl https://huggingface.co/datasets/towardsai-buster/llama-index-docs/raw/main/llama_index_data_150k.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZZLK_wyEc-L"
      },
      "source": [
        "## Read File and create LlamaIndex Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "miUqycqAEfr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb12e48-2add-4070-b08c-6924280cb691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents: 56\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import Document\n",
        "import json\n",
        "\n",
        "\n",
        "def create_docs(input_file: str) -> list[Document]:\n",
        "    documents = []\n",
        "    with open(input_file, \"r\") as f:\n",
        "        for idx, line in enumerate(f, start=1):\n",
        "\n",
        "          data = json.loads(line)\n",
        "\n",
        "          required_keys = {\"doc_id\", \"content\", \"url\", \"name\", \"tokens\", \"source\"}\n",
        "          if not required_keys.issubset(data):\n",
        "              print(f\"Missing keys in line {idx}: {required_keys - set(data)}\")\n",
        "              continue\n",
        "\n",
        "          documents.append(\n",
        "              Document(\n",
        "                  doc_id=data[\"doc_id\"],\n",
        "                  text=data[\"content\"],\n",
        "                  metadata={  # type: ignore\n",
        "                      \"url\": data[\"url\"],\n",
        "                      \"title\": data[\"name\"],\n",
        "                      \"tokens\": data[\"tokens\"],\n",
        "                      \"source\": data[\"source\"],\n",
        "                  },\n",
        "                  excluded_llm_metadata_keys=[\n",
        "                      \"title\",\n",
        "                      \"tokens\",\n",
        "                      \"source\",\n",
        "                  ],\n",
        "                  excluded_embed_metadata_keys=[\n",
        "                      \"url\",\n",
        "                      \"tokens\",\n",
        "                      \"source\",\n",
        "                  ],\n",
        "              )\n",
        "          )\n",
        "\n",
        "    return documents\n",
        "\n",
        "\n",
        "# Convert the texts to Document objects.\n",
        "documents = create_docs(\"llama_index_150k.jsonl\")\n",
        "print(f\"Number of documents: {len(documents)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86yksB9K571"
      },
      "source": [
        "# Generate Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "00b8b0200f2c4ba9a2f74f459449001c",
            "4bab977b544a47e0a91611a1d4eaa596",
            "7293ec2adb5c4b9794eaf47af0eafb3f",
            "17d9ea7e1edb4e7aaeb07aed3bc1ad15",
            "dbc0a23f76344eea923971f26aaeaacf",
            "9dac0330ee0f4b1e96e4aca4a63f2646",
            "4a84e4c1b2cc40328c71ff2311db33d4",
            "d3a9407e4ba241d28a8b0ee35cbe6cdb",
            "d8d4affcdaf44fc7818856867add2691",
            "24d7500c61984fd5ab0396e16421675d",
            "00ff78933096496f846560c23e937a8d",
            "117b0e338b7f4e5cbdc8f55ea43e07cd",
            "f7cc697293b14db1b52b9c4333a8499a",
            "ed238ac3ff22442ca0cff8766b7405e6",
            "e2502294e69b4a79a435782d22962d55",
            "23434b53312147df8ecb184bfbd79b3f",
            "ffd1f6396a394e66b11c500b3b847711",
            "13e4f88a2cd64829bd538ee92813213d",
            "3bb798edfaa9410983128c92b18523d2",
            "a7af57edbc534d559cb6bb922e417e6d",
            "407f6db8ec274783b43c527bfcf00777",
            "6749f01ae0e34c769cdcf7b76afea963"
          ]
        },
        "id": "Bsa7Q-DoNWBk",
        "outputId": "cc795537-4d91-4ef4-e98b-62d213b49a37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/56 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00b8b0200f2c4ba9a2f74f459449001c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/447 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "117b0e338b7f4e5cbdc8f55ea43e07cd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "\n",
        "# Build index / generate embeddings using OpenAI embedding model\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    embed_model=OpenAIEmbedding(model=\"text-embedding-3-small\"),\n",
        "    transformations=[SentenceSplitter(chunk_size=512, chunk_overlap=128)],\n",
        "    show_progress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DoUxd8KK--Q"
      },
      "source": [
        "# Query Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bUaNH97dEfh9"
      },
      "outputs": [],
      "source": [
        "# Define a query engine that is responsible for retrieving related pieces of text,\n",
        "# and using a LLM to formulate the final answer.\n",
        "\n",
        "from llama_index.llms.gemini import Gemini\n",
        "\n",
        "llm = Gemini(model=\"models/gemini-1.5-flash\", temperature=1, max_tokens=1000)\n",
        "\n",
        "query_engine = index.as_query_engine(llm=llm, similarity_top_k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "KHK4V_GRR6ZG",
        "outputId": "bbe58137-aaff-435c-957f-bbe0cbcb7977"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "First, build an index using a method like `VectorStoreIndex.from_documents(documents)`. Then, create a query engine from your index with `index.as_query_engine()`. You can then query the engine with `query_engine.query(\"Your query here\")`. \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  3.2618541717529297\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "response = query_engine.query(\"How to setup a query engine in code?\")\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "display(Markdown(response.response))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "S-BmyTBbNd9y",
        "outputId": "b924c74e-a8e2-4a27-f177-98e35e69d540"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Start by importing the necessary components from LlamaIndex and loading your environment variables.  Define two basic tools, one for multiplying numbers and one for adding them, by creating Python functions and wrapping them in `FunctionTool` objects. Initialize an LLM, such as `GPT-3.5-Turbo`, using the `OpenAI` class. Finally, create your agent using the `ReActAgent` class, providing it with your tools and the initialized LLM.  \n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  2.558102607727051\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "response = query_engine.query(\"How to setup an agent in code?\")\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "display(Markdown(response.response))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_55vnPoSlID"
      },
      "source": [
        "# Setup Long Context Caching\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBSZTxjfSlID"
      },
      "source": [
        "For this section, we will be using the Gemini API\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"You might encounter dependency issues, so reinstall google-generativeai to the latest version. To use long context caching in google-generativeai,\n",
        "you will need version > 0.7.2. \"\"\"\n",
        "\n",
        "!pip install -q google-generativeai==0.8.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-xVY9mXk-eN",
        "outputId": "cf8278b8-af0a-4109-cb52-699f6dbb01c5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-llms-gemini 0.3.7 requires google-generativeai<0.6.0,>=0.5.2, but you have google-generativeai 0.8.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eGIFfZrBSlID"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.generativeai import caching\n",
        "from google.generativeai import GenerationConfig\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex4X8BE3SlIE"
      },
      "source": [
        "Convert the jsonl file to a text file for the Gemini API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bcL6M1VpSlIE",
        "outputId": "109438d6-b5d8-4158-b578-6b61c35cbaff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents saved to llama_index_contents.txt\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "\n",
        "def create_text_file(input_file: str, output_file: str) -> None:\n",
        "    with open(input_file, \"r\") as f, open(output_file, \"w\") as out:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            out.write(data[\"content\"] + \"\\n\\n\")  # Add two newlines between documents\n",
        "\n",
        "    print(f\"Contents saved to {output_file}\")\n",
        "\n",
        "\n",
        "create_text_file(\"llama_index_150k.jsonl\", \"llama_index_contents.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "l2S4vl3ySlIE"
      },
      "outputs": [],
      "source": [
        "document = genai.upload_file(path=\"llama_index_contents.txt\")\n",
        "model_name = \"gemini-1.5-flash-001\"\n",
        "\n",
        "cache = genai.caching.CachedContent.create(\n",
        "    model=model_name,\n",
        "    system_instruction=\"You answer questions about the LlamaIndex framework.\",\n",
        "    contents=[document],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GsPYVW6hSlIF",
        "outputId": "1d572460-4ba0-4192-b881-c07433a14654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here's a breakdown of how to set up a query engine in LlamaIndex, along with key concepts and code examples:\n\n**Understanding Query Engines**\n\n* **Core Functionality:** A query engine is the heart of your LlamaIndex application. It acts as an interface between a user's natural language question and the underlying data stored in an index. \n* **Bridging the Gap:** Query engines handle the complex steps of retrieval, processing, and response synthesis to deliver coherent answers to users.\n* **Customizable:** LlamaIndex offers a flexible architecture, allowing you to configure query engines for specific use cases and optimize performance.\n\n**Key Components of a Query Engine**\n\n* **Index:**  The data structure that holds your information, which can be a `VectorStoreIndex`, `TreeIndex`, `SummaryIndex`, or other specialized indexes.\n* **Retriever:** This determines how the query engine retrieves relevant information from the index. Common options include `VectorIndexRetriever` for semantic search and `KeywordTableRetriever` for keyword-based retrieval.\n* **Node Postprocessors:** These components can be used to filter, re-rank, or augment retrieved nodes (text chunks) before they're sent to the LLM.\n* **Response Synthesizer:** This component handles the final step of combining the retrieved information with the user's query and then prompting the LLM to generate a coherent response. \n\n**Code Examples**\n\n1. **Simple VectorStoreIndex Query Engine:**\n\n   ```python\n   from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n   from llama_index.llms.openai import OpenAI\n\n   # 1. Load your documents\n   documents = SimpleDirectoryReader(\"path/to/your/documents\").load_data()\n\n   # 2. Create a VectorStoreIndex\n   index = VectorStoreIndex.from_documents(documents)\n\n   # 3. Create the QueryEngine \n   query_engine = index.as_query_engine()\n\n   # 4. Run a query\n   response = query_engine.query(\"What is the main point of this document?\")\n   print(response) \n   ```\n\n2. **Customizing Retrieval:** \n\n   ```python\n   from llama_index.core import VectorStoreIndex, get_response_synthesizer\n   from llama_index.core.retrievers import VectorIndexRetriever\n   from llama_index.core.query_engine import RetrieverQueryEngine\n   from llama_index.core.postprocessor import SimilarityPostprocessor\n\n   # ... (Load your documents and create an index as above)\n\n   # 1. Create a custom retriever \n   retriever = VectorIndexRetriever(\n       index=index,\n       similarity_top_k=5, # Return the top 5 most similar nodes \n   )\n\n   # 2. Create a response synthesizer \n   response_synthesizer = get_response_synthesizer()\n\n   # 3. Create the query engine\n   query_engine = RetrieverQueryEngine(\n       retriever=retriever,\n       response_synthesizer=response_synthesizer,\n       node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)]\n   )\n\n   # 4. Run a query\n   response = query_engine.query(\"What is the main point of this document?\")\n   print(response) \n   ```\n\n3. **Adding a Keyword Postprocessor:**\n\n   ```python\n   from llama_index.core import VectorStoreIndex, get_response_synthesizer\n   from llama_index.core.retrievers import VectorIndexRetriever\n   from llama_index.core.query_engine import RetrieverQueryEngine\n   from llama_index.core.postprocessor import KeywordNodePostprocessor\n\n   # ... (Load your documents and create an index as above)\n\n   # 1. Create a custom retriever \n   retriever = VectorIndexRetriever(\n       index=index,\n       similarity_top_k=5, \n   )\n\n   # 2. Create a response synthesizer \n   response_synthesizer = get_response_synthesizer()\n\n   # 3. Create the query engine\n   query_engine = RetrieverQueryEngine(\n       retriever=retriever,\n       response_synthesizer=response_synthesizer,\n       node_postprocessors=[KeywordNodePostprocessor(required_keywords=[\"company\", \"growth\"])] \n   )\n\n   # 4. Run a query\n   response = query_engine.query(\"What is the company's growth strategy?\")\n   print(response) \n   ```\n\n**Key Points**\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken:  19.9561128616333\n"
          ]
        }
      ],
      "source": [
        "model = genai.GenerativeModel.from_cached_content(cache)\n",
        "start = time.time()\n",
        "response = model.generate_content(\n",
        "    \"How to setup a query engine in code?\",\n",
        "    generation_config=GenerationConfig(max_output_tokens=1000),\n",
        ")\n",
        "end = time.time()\n",
        "display(Markdown(response.text))\n",
        "print(\"time taken: \", end - start)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXYAFNsFTXmi"
      },
      "execution_count": 17,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00b8b0200f2c4ba9a2f74f459449001c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bab977b544a47e0a91611a1d4eaa596",
              "IPY_MODEL_7293ec2adb5c4b9794eaf47af0eafb3f",
              "IPY_MODEL_17d9ea7e1edb4e7aaeb07aed3bc1ad15"
            ],
            "layout": "IPY_MODEL_dbc0a23f76344eea923971f26aaeaacf"
          }
        },
        "4bab977b544a47e0a91611a1d4eaa596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dac0330ee0f4b1e96e4aca4a63f2646",
            "placeholder": "​",
            "style": "IPY_MODEL_4a84e4c1b2cc40328c71ff2311db33d4",
            "value": "Parsing nodes: 100%"
          }
        },
        "7293ec2adb5c4b9794eaf47af0eafb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3a9407e4ba241d28a8b0ee35cbe6cdb",
            "max": 56,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8d4affcdaf44fc7818856867add2691",
            "value": 56
          }
        },
        "17d9ea7e1edb4e7aaeb07aed3bc1ad15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24d7500c61984fd5ab0396e16421675d",
            "placeholder": "​",
            "style": "IPY_MODEL_00ff78933096496f846560c23e937a8d",
            "value": " 56/56 [00:00&lt;00:00, 57.00it/s]"
          }
        },
        "dbc0a23f76344eea923971f26aaeaacf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dac0330ee0f4b1e96e4aca4a63f2646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a84e4c1b2cc40328c71ff2311db33d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3a9407e4ba241d28a8b0ee35cbe6cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d4affcdaf44fc7818856867add2691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24d7500c61984fd5ab0396e16421675d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00ff78933096496f846560c23e937a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "117b0e338b7f4e5cbdc8f55ea43e07cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7cc697293b14db1b52b9c4333a8499a",
              "IPY_MODEL_ed238ac3ff22442ca0cff8766b7405e6",
              "IPY_MODEL_e2502294e69b4a79a435782d22962d55"
            ],
            "layout": "IPY_MODEL_23434b53312147df8ecb184bfbd79b3f"
          }
        },
        "f7cc697293b14db1b52b9c4333a8499a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd1f6396a394e66b11c500b3b847711",
            "placeholder": "​",
            "style": "IPY_MODEL_13e4f88a2cd64829bd538ee92813213d",
            "value": "Generating embeddings: 100%"
          }
        },
        "ed238ac3ff22442ca0cff8766b7405e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb798edfaa9410983128c92b18523d2",
            "max": 447,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7af57edbc534d559cb6bb922e417e6d",
            "value": 447
          }
        },
        "e2502294e69b4a79a435782d22962d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_407f6db8ec274783b43c527bfcf00777",
            "placeholder": "​",
            "style": "IPY_MODEL_6749f01ae0e34c769cdcf7b76afea963",
            "value": " 447/447 [00:05&lt;00:00, 73.00it/s]"
          }
        },
        "23434b53312147df8ecb184bfbd79b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd1f6396a394e66b11c500b3b847711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e4f88a2cd64829bd538ee92813213d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb798edfaa9410983128c92b18523d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7af57edbc534d559cb6bb922e417e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "407f6db8ec274783b43c527bfcf00777": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6749f01ae0e34c769cdcf7b76afea963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}