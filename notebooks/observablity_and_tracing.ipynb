{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "AItauLdsp7jj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmnledOoOjbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a423b379-25cc-47f5-cb81-185cf649210a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install langchain-openai==0.2.3 langchain==0.3.4 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up env"
      ],
      "metadata": {
        "id": "AgSc92W9qIeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<OPENAI_API_KEY\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"<LANGCHAIN_API_KEY>\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"<LANGCHAIN_PROJECT>\""
      ],
      "metadata": {
        "id": "lXz2mUoyiEuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracing Langchain calls"
      ],
      "metadata": {
        "id": "LAgKNo9kqOZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull(\"wikianes/section_writer\")\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "chain = prompt | llm\n",
        "output = chain.invoke({\"section_description\": \"Quantum Physics\"})\n",
        "print(output.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okLDL4YQhljS",
        "outputId": "872b6cf2-da3f-4c7e-ec1a-7f254a41c7d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Quantum Physics in Anesthesia\n",
            "\n",
            "## Introduction to Quantum Physics in Medicine\n",
            "Quantum physics, the study of matter and energy at the atomic and subatomic levels, has increasingly influenced various fields of medicine, including anesthesiology. Understanding the principles of quantum mechanics can enhance anesthesiologists' comprehension of drug interactions and the mechanisms of action of anesthetic agents, ultimately improving patient outcomes during surgical procedures.\n",
            "\n",
            "## Quantum Effects on Drug Mechanisms\n",
            "Anesthetic agents operate through complex interactions at the molecular level, influenced by quantum phenomena. For example, the binding affinity of anesthetic drugs to their target receptors can be affected by quantum tunneling and superposition. These principles can help explain variations in anesthesia depth and duration, as well as individual patient responses to anesthetic agents. Anesthesiologists should consider these quantum effects when selecting agents, especially in patients with unique metabolic profiles.\n",
            "\n",
            "## Implications for Anesthetic Practice\n",
            "### Preoperative Assessment\n",
            "An understanding of quantum effects can inform preoperative assessments, particularly in predicting how patients might metabolize anesthetic drugs. Factors such as age, genetic polymorphisms, and underlying health conditions can alter quantum interactions, necessitating careful evaluation of patient history and potential drug interactions. \n",
            "\n",
            "### Personalized Anesthesia\n",
            "Quantum principles pave the way for personalized anesthesia approaches. By anticipating how individual patient characteristics affect the pharmacodynamics and pharmacokinetics of anesthetics, anesthesiologists can tailor drug dosages and combinations. This customization can minimize adverse effects and enhance the efficacy of anesthesia, particularly in high-risk patients or complex surgical procedures.\n",
            "\n",
            "### Monitoring and Technology\n",
            "Advancements in quantum technology, such as quantum sensors, have the potential to revolutionize patient monitoring during anesthesia. These sensors can provide real-time data on physiological parameters with unprecedented accuracy, allowing for more precise titration of anesthetic agents and improved safety profiles. Anesthesiologists should stay abreast of these technological developments to integrate them into practice effectively.\n",
            "\n",
            "## Conclusion\n",
            "While quantum physics may seem abstract, its principles are increasingly relevant to anesthetic practice. By understanding quantum interactions at the molecular level, anesthesiologists can enhance their approach to drug selection, patient assessment, and monitoring during surgical procedures, leading to improved outcomes and safety for patients. As research in this area continues to evolve, the integration of quantum physics into anesthesiology will likely become more pronounced, necessitating ongoing education and adaptation within the field.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracing OpenAI calls"
      ],
      "metadata": {
        "id": "0-s3VBrSzkXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from langsmith.wrappers import wrap_openai\n",
        "\n",
        "# wrap_openai from langsmith provides wrapper to\n",
        "ai_client = wrap_openai(OpenAI())\n",
        "\n",
        "\n",
        "def retrieve_documents(inquiry: str):\n",
        "    docs = [\n",
        "        \"Vector databases enable efficient semantic search for LLMs.\",\n",
        "        \"Retrieval-Augmented Generation (RAG) improves LLM accuracy with relevant context.\",\n",
        "        \"Large Language Models (LLMs) have set new benchmarks in NLP tasks.\",\n",
        "        \"Transformer architectures have revolutionized many areas of machine learning.\",\n",
        "        \"Embedding models convert text into vector representations for similarity comparisons.\"\n",
        "    ]\n",
        "    return docs\n",
        "\n",
        "def ask_qa(query):\n",
        "    context = retrieve_documents(query)\n",
        "    system_prompt = f\"\"\"\n",
        "    You are an assistant for question-answering tasks.\n",
        "    Use the following pieces of retrieved context to answer the question.\n",
        "    Context: {context}\n",
        "    \"\"\"\n",
        "\n",
        "    return ai_client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": query},\n",
        "        ],\n",
        "        model=\"gpt-4o-mini\",\n",
        "    )"
      ],
      "metadata": {
        "id": "1sM6lLW2sFT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_qa(\"what is vector db?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_sGUKNusXcA",
        "outputId": "89ab6371-d654-4ad7-a9a8-92fc82321356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-ALZOOE9lCSqi9VO0o847Qwo3Xc2FI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A vector database is a type of database designed to store and manage vector representations of data, particularly for efficient semantic search and similarity comparisons. These vectors are often generated by embedding models, which convert text or other data types into numerical vectors. Vector databases enable quick retrieval of information by allowing for searches based on semantic similarity rather than relying solely on keyword matching. This functionality is particularly useful for applications involving Large Language Models (LLMs), as it facilitates Retrieval-Augmented Generation (RAG) by providing relevant context that enhances model accuracy.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1729704300, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_482c22a7bc', usage=CompletionUsage(completion_tokens=105, prompt_tokens=116, total_tokens=221, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Langsmith traceable decorator"
      ],
      "metadata": {
        "id": "-2Inyx_2FPuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from langsmith import traceable\n",
        "\n",
        "openai_client = OpenAI()\n",
        "\n",
        "@traceable(run_type=\"llm\", name=\"OpenAI call\")\n",
        "def call_llm(model, messages):\n",
        "    result = openai_client.chat.completions.create(\n",
        "            messages=messages,\n",
        "            model=model\n",
        "        )\n",
        "    return result.choices[0].message.content\n",
        "\n",
        "\n",
        "@traceable(run_type=\"retriever\")\n",
        "def retrieve_documents(inquiry: str):\n",
        "    docs = [\n",
        "        \"Vector databases enable efficient semantic search for LLMs.\",\n",
        "        \"Retrieval-Augmented Generation (RAG) improves LLM accuracy with relevant context.\",\n",
        "        \"Large Language Models (LLMs) have set new benchmarks in NLP tasks.\",\n",
        "        \"Transformer architectures have revolutionized many areas of machine learning.\",\n",
        "        \"Embedding models convert text into vector representations for similarity comparisons.\"\n",
        "    ]\n",
        "    return docs\n",
        "\n",
        "@traceable(run_type=\"chain\")\n",
        "def ask_qa(query):\n",
        "    context = retrieve_documents(query)\n",
        "    system_prompt = f\"\"\"\n",
        "    You are an assistant for question-answering tasks.\n",
        "    Use the following pieces of retrieved context to answer the question.\n",
        "    Context: {context}\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "    ]\n",
        "    return call_llm(\"gpt-4o-mini\", messages)"
      ],
      "metadata": {
        "id": "wzkrlI7Hsa54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ask_qa(\"What are large language models\", langsmith_extra={\"metadata\": {\"user\": \"test_user@gmail.com\"}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "IvUZtIjFFmyB",
        "outputId": "cf498afa-f52d-4c60-e8b9-d59cb5928adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Large Language Models (LLMs) are advanced AI systems designed to understand and generate human-like text. They have set new benchmarks in various natural language processing (NLP) tasks by utilizing massive datasets and sophisticated architectures, particularly transformer architectures. LLMs leverage techniques such as Retrieval-Augmented Generation (RAG) to enhance their accuracy and effectiveness by incorporating relevant context into their responses. Additionally, embedding models are often used in conjunction with LLMs to convert text into vector representations, facilitating efficient semantic search and similarity comparisons.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sjEzBXy8aGdy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}